{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado de Tópicos \n",
    "\n",
    "Este *cuaderno* trata sobre modelado de tópicos a partir de datos de texto. El objetivo del *cuaderno* es que usted obtenga una visión general del modelo de asignación latente de Dirichlet (LDA, por sus siglas en inglés). Busca también que sea capaz de crear e implementar este modelo en `Python` y que sea  capaz de evaluar e interpretar los resultados, y de identificar el mejor modelo de tópicos para un determinado problema. \n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Sin embargo, los ejemplos contienen celdas con código ejecutable (`en gris`), que podrá modificar  libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los códigos de ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Todo texto presenta una variedad de tópicos o temas que  se expresan a través  de palabras. El modelado de tópicos o temas es una faceta del procesamiento del lenguaje natural (NLP, por sus siglas en inglés). Como vimos anteriormente, utilizar el lenguaje, textos, como datos puede ser extremadamente poderoso. \n",
    "\n",
    "En este *cuaderno* nos centraremos sobre el modelado de tópicos. Inmediatamente nos surge la pregunta ¿qué son los tópicos? Responderemos esa pregunta con un ejemplo. Habremos notado que en los días en que se llevan a cabo eventos importantes (como elecciones nacionales, desastres naturales o eventos deportivos), las publicaciones de las redes sociales tienden a centrarse en esos eventos. Las publicaciones de alguna manera reflejan los eventos del día, y lo hacen de diferentes formas. Las publicaciones pueden tener, puntos de vista divergentes que permiten que las agrupemos en grupos o clústeres de tópicos. Por ejemplo, si tuviéramos tweets sobre la final del Mundial, los tópicos de esos tweets podrían cubrir puntos de vista divergentes, que van desde la calidad del arbitraje al comportamiento de los aficionados. Esto lo lograríamos agrupando las publicaciones usando las palabras claves contenidas en ellos. Por ejemplo, la siguiente figura con un breve texto sobre ciencia de datos muestra cómo se pueden identificar palabras y asignarlas a tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/topicos1.jpeg\" alt = \"topicos\" style = \"width: 500px;\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En  la figura se muestra cómo palabras como información, predicción, y estadística, son asignadas al tópico de modelado; mientras que computacional, producción y escala son asignadas al tópico de ingeniería. Los modelos de tópicos son importantes porque ofrecen la misma función para los datos textuales que las estadísticas clásicas para los datos numéricos. Es decir, proporcionan un resumen significativo de los datos. \n",
    "\n",
    "Los modelos de tópicos entran en la categoría de aprendizaje no supervisado porque, casi siempre, no se conocen de antemano los tópicos subyacentes de los documentos. Por lo tanto, no existe una variable que guíe el aprendizaje. En términos de aprendizaje no supervisado, los modelos de tópicos se pueden pensar como parte del análisis de clusters, más específicamente a K-medias. Recordemos que con K-medias, primero se establece el número de clusters y luego el modelo asigna cada uno de los datos a uno de los clústers predeterminados. Lo mismo ocurre generalmente con los modelos de tópicos. Seleccionamos el número de tópicos al inicio y luego el modelo aísla las palabras que forman esa cantidad de tópicos. Este es un excelente punto de partida para una descripción general de modelado de tópicos de alto nivel.\n",
    "\n",
    "\n",
    "Los modelos de tópicos buscan encontrar patrones comunes en el texto en el sentido de que los documentos describen tópicos similares. Es decir, estos modelos identifican los tópicos abstractos en una colección de documentos (también referidos como corpus), utilizando las palabras contenidas en los documentos.  Para ello asumen que las palabras en el mismo documento están relacionadas y usan esa suposición para definir tópicos abstractos al encontrar grupos de palabras que aparecen con frecuencia una cerca de otra.  Por ejemplo, si una oración contiene las palabras salario, empleado, y reunión, podemos asumir que esa oración trata o que su tópico es el trabajo.\n",
    "\n",
    "Este tipo de algoritmos por lo general pretenden primero determinar el número de tópicos, luego identificar palabras o frases concurrentes en los documentos; y a partir de esto, buscar clusters de palabras que caracterizan el documento y finalmente retornar un conjunto de tópicos abstractos que caracterizan el corpus.\n",
    "\n",
    "Un aspecto clave de los modelos de tópicos es que no producen tópicos específicos de una palabra o una frase, sino un conjunto de palabras, cada una de las cuales representa un tópico abstracto. Esto se debe a que los modelos de tópicos entienden la proximidad de las palabras, no el contexto. Por ejemplo, en la figura siguiente, el modelo no tiene idea de lo que significan ala, elevar, piloto, equipaje, pasajero, o mosca; sólo sabe que estas palabras, generalmente, siempre que aparecen, aparecen muy próximas entre sí. Será nuestra tarea darle una interpretación (o no) a este tópico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/topicos3.jpeg\" alt = \"topicos3\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varios algoritmos de modelado de tópicos, pero quizás el más conocidos es el de Asignación Latente de Dirichlet, o Latent Dirichlet Allocation (LDA) en inglés. En este *cuaderno* nos centraremos en este."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación Latente de Dirichlet (LDA)\n",
    "\n",
    "En 2003, David Blei, Andrew Ng, y Michael Jordan publicaron un artículo sobre el algoritmo del modelado de tópicos conocido como Latent Dirichlet Allocation (LDA). LDA es un modelo probabilístico generativo, esto significa que el proceso de modelado comienza con el texto y funciona como ingeniería reversa a través del proceso que suponemos que lo generó, con el fin de identificar los parámetros de interés. En este caso, son los tópicos que generaron los datos que son de interés. \n",
    "\n",
    "Esencialmente LDA es una técnica de clustering que puede ser aplicada a colecciones de datos discretos como los son los documentos de texto. LDA es un modelo bayesiano jerárquico de 3 niveles en donde cada elemento o palabra de un texto se modela como una mezcla finita de tópicos. A su vez, cada tópico se modela como una combinación infinita de palabras. \n",
    "\n",
    "Esta técnica de aprendizaje no supervisado se diferencia de las técnicas de clustering estudiadas anteriormente porque en este caso cada observación pertenece a más de un grupo, donde la pertenencia de un elemento a un grupo se modela como una distribución de probabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up del modelo\n",
    "\n",
    "LDA representa los documentos como una mezcla de tópicos que generan palabras con ciertas probabilidades. Asume  que los documentos se generan siguiendo un proceso definido. Al empezar a escribir un documento:\n",
    "\n",
    "1. Decidimos el número de palabras que el documento tendrá, que surge de una distribución de Poisson.\n",
    "2. Elegimos la mezcla de tópicos del documento, esta mezcla surge de una distribución de Dirichlet sobre un conjunto fijo de K tópicos. Por ejemplo, siguiendo el ejemplo anterior, podríamos elegir que el documento consista 1/3 sobre aviones y 2/3 sobre automóviles. Intuitivamente, cuando utilizamos la distribución de Dirichlet estamos asumiendo que los documentos dentro del corpus se distribuirían a lo largo del simplex en donde cada vértice se representa un tópico. Luego, cada documento se ubicaría más cercano a los vértices que representan los tópicos contenidos en él. Por ejemplo, supongamos que tenemos 7 documentos y 3 tópicos posibles (aviones, automóviles y barcos), podríamos representar los documentos dentro del simplex  de la siguiente manera:\n",
    "\n",
    "<center>\n",
    "<img src = \"figs/Triangulo.png\" alt = \"LDA\" style = \"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "   De esta manera podríamos ver que cada documento es una combinación de tópicos. El documento 1 sería 100% sobre aviones, el documento 2 sería 50% sobre aviones y 50% sobre automóviles, el documento 5 sería 100% sobre barcos, etc.\n",
    "\n",
    "\n",
    "3. Generamos cada palabra en el documento siguiendo el siguiente esquema:\n",
    "    \n",
    "    3.1. Elegimos un tópico, de acuerdo con la distribución multinomial que muestreamos en el paso anterior, por ejemplo, podemos elegir el tópico de aviones con probabilidad 1/3 y el tópico de automóviles con 2/3.\n",
    "    \n",
    "    3.2 Usando el tópico generamos la palabra (de acuerdo con la distribución multinomial). Por ejemplo, si seleccionamos el tópico de aviones, podríamos generar la palabra “piloto” con probabilidad del 20%, y “equipaje” con probabilidad del 10%, y así sucesivamente.\n",
    "\n",
    "Formalmente, definimos una palabra como un ítem de un vocabulario indexado por $\\{1, \\cdots, V\\}$. Las palabras se representan  mediante vectores de base uno, es decir, un vector donde sólo un elemento es 1 y el resto son 0. Así, usando superíndices para denotar componentes, la v-ésima palabra en el vocabulario se representa mediante un V-vector $w$ tal que $w^v = 1$ y $w^u = 0$ para $u\\neq v$. Un *documento* es una secuencia de $N$ palabras denotadas por $\\mathbf{w}=(w_1,w_2,\\cdots,w_N)$, en donde $w_n$ es la n-ésima palabra de la secuencia. Un *corpus* es una colección de $M$ documentos denotados por $\\mathbf{D}=(\\mathbf{w_1},\\mathbf{w_2},\\cdots,\\mathbf{w_m})$.\n",
    "\n",
    "Así, para cada documento del corpus $D$, LDA supone los siguientes pasos que generan  cada documento:\n",
    "\n",
    "1. Decidimos $N\\sim Poisson(\\xi)$, donde $N$ son palabras del documento que surgen de un proceso de Poisson  con parámetro $\\xi$\n",
    "2. Elegimos  $\\theta\\sim Dir(\\alpha)$ donde $\\theta$  es la distribución de tópicos que asumimos surgen de una distribución Dirichlet con $K$ categorias.\n",
    "3. Generamos $N$ palabras, $w_n$:\n",
    "\n",
    "    3.1. Elegimos un tópico $z_n\\sim Multinomial(\\theta)$, de una distribución multiomial con parámetro $\\theta$\n",
    "  \n",
    "    3.2 Usando el tópico generamos $w_n$ de $p(w_n|z_n, \\beta)$\n",
    "\n",
    "\n",
    "Estos 3 pasos se repiten para cada documento en el corpus.\n",
    "\n",
    "Es importante que notemos que este modelo inicial cuenta con algunas simplificaciones:   \n",
    "\n",
    "  - En primer lugar, la dimensionalidad $K$ de la distribución Dirichlet (y por consiguiente la dimensionalidad de la variable de los tópicos $z$) se supone fija y conocida. \n",
    "  - Segundo, las probabilidades de cada palabra son parametrizadas por una matriz $\\beta$ de tamaño $k\\times V$ en donde $\\beta_{ij}=p(w^j = 1|z^i = 1)$, que trataremos como una cantidad fija que será estimada. \n",
    "\n",
    "Tomando como dados los parámetros $\\alpha$ y $\\beta$, la distribución de probabilidad conjunta de una mezcla de tópicos $\\theta$, un conjunto de $N$ temas $\\mathbf{z}$ y un conjunto de $N$ palabras $\\mathbf{w}$ esta dada por:\n",
    "\n",
    "$$p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta) = p(\\theta|\\alpha)\\prod_{n=1}^N p(z_n|\\theta)p(w_n|z_n, \\beta)$$\n",
    "\n",
    "Notemos que el lado izquierdo de esta ecuación ($p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta)$) corresponde a la probabilidad de que un documento $x$ aparezca en nuestro corpus. De este modo, nuestro objetivo será estimar $\\alpha$ y $\\beta$ de modo que se maximice la probabilidad de encontrar nuestra muestra de documentos.\n",
    "\n",
    "Podemos representar la solución LDA a través de una gráfica, que nos permitirá entender un poco mejor la intuición detrás del problema: \n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src = \"figs/topicos4.jpeg\" alt = \"LDA1\" style = \"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "Las cajas son \"placas\" que utilizamos  para representar los 2 pasos iterativos del proceso. Dado que el proceso lo ejecutamos para cada documento del corpus, la placa externa (etiquetada como M) representa la iteración sobre cada documento. Mientras que, la iteración sobre palabras en el Paso 3 está representada por la placa  interna del diagrama, etiquetada como N. Los círculos representan los parámetros, las distribuciones y los resultados. El círculo etiquetado como W es la palabra seleccionada, que es el único dato conocido y, como tal, se utiliza para realizar \"ingeniería inversa\" en el proceso. Además de W, las otras 4 variables en el diagrama se definen de la siguiente manera:\n",
    "\n",
    "- $\\alpha$: hiperparámetro del documento del tópico para la distribución de Dirichlet.\n",
    "- $\\beta$: distribución de palabras para cada tópico.\n",
    "- $z$: variable latente del tópico.\n",
    "- $\\theta$: variable latente para la distribución de tópicos de cada documento.\n",
    "\n",
    "$\\alpha$ y $\\beta$ controlan la frecuencia de tópicos de los documentos y la frecuencia de palabra en los tópicos. Si $\\alpha$ aumenta, los documentos se vuelven cada vez más similares a medida que aumenta el número de tópicos en cada documento. Por otro lado, si $\\alpha$ disminuye, los documentos se vuelven cada vez más disímiles a medida que disminuye el número de tópicos en cada documento. \n",
    "\n",
    "El parámetro $\\beta$  se comporta de manera similar. Si $\\beta$ aumenta, se usan más palabras del documento para modelar un tópico, mientras que un valor más bajo hace que se use una cantidad menor de palabras para un tópico. Dada la complejidad de las distribuciones en LDA, no existe una solución directa, por lo que se requiere algún tipo de algoritmo de aproximación para generar los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencia variacional\n",
    "\n",
    "El principal desafío  de este modelo es el cálculo de la distribución posterior:\n",
    "\n",
    "$$p(\\theta, \\mathbf{z}|\\mathbf{w},\\alpha, \\beta)=\\frac{p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta)}{p(\\mathbf{w}|\\alpha, \\beta)}$$\n",
    "\n",
    "Desafortunadamente, esta distribución no se puede calcular directamente, por ende se debe aproximar numéricamente. La inferencia variacional es uno de los algoritmos de aproximación más simples, pero tiene una derivación extensa que requiere un conocimiento significativo de la probabilidad y es material para cursos más avanzados.\n",
    "\n",
    "Sin embargo, en este *cuaderno* describiremos la intuición detrás de un algoritmo variacional simple basado en la convexidad. \n",
    "\n",
    "#### Intuición\n",
    "\n",
    "\n",
    "La intuición detrás de la inferencia variacional es que, si la distribución real es intratable, entonces se debe encontrar una distribución más simple, llamémosla distribución variacional, muy cercana a la distribución verdadera, que es manejable, para que la inferencia sea posible. En otras palabras, dado que es imposible inferir la distribución real debido a su  complejidad, buscamos encontrar una distribución más simple que sea una buena aproximación de la distribución real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/topicos5.jpeg\" alt = \"LDA1\" style = \"width: 500px;\"/>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inferencia variacional es como tratar de ver animales en un zoológico lleno de gente. Los animales del zoológico están en un hábitat cerrado que, en este ejemplo, es la distribución posterior. Los visitantes en realidad no pueden ingresar al hábitat, por lo que los visitantes deben conformarse con ver el hábitat desde la posición más cercana posible, que es la aproximación posterior (es decir, la mejor aproximación del hábitat). Si hay mucha gente en el zoológico, puede ser difícil llegar a ese punto de vista óptimo. La gente generalmente comienza en la parte de atrás de la multitud y avanza estratégicamente hacia ese punto de vista óptimo. El paso de los visitantes desde la parte trasera de la multitud al punto de vista óptimo es el camino de optimización. La inferencia variacional es simplemente el proceso de acercarse lo mejor posible al punto deseado sabiendo que en realidad no se puede alcanzar el punto deseado.\n",
    "\n",
    "Con la intuición  desarrollada veamos una aplicación en `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA en `Python`\n",
    "\n",
    "\n",
    "Ilustremos ahora la implementación de LDA en `Phyton`. Para ello vamos a usar textos que contienen  páginas sobre distintos ensayos. Por la frecuencia de palabras tenemos la sospecha de que estas páginas se refieren a [Chomsky](https://en.wikipedia.org/wiki/Noam_Chomsky), [Freud](https://en.wikipedia.org/wiki/Sigmund_Freud), y [Voltaire](https://en.wikipedia.org/wiki/Voltaire). El objetivo será entonces ver si podemos encontrar de forma no supervisada estas páginas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>titulo</th>\n",
       "      <th>pagina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introducción Noam Chomsky. Avram Noam Chomsky ...</td>\n",
       "      <td>Chomsky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toda su construcción intelectual. Si de algo n...</td>\n",
       "      <td>Chomsky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tales como la ya lejana Guerra de Vietnam (la ...</td>\n",
       "      <td>Chomsky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un sistema de financiación sin parangón, que d...</td>\n",
       "      <td>Chomsky</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de la lingüística y de las ciencias cognitivas...</td>\n",
       "      <td>Chomsky</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto   titulo  pagina\n",
       "0  Introducción Noam Chomsky. Avram Noam Chomsky ...  Chomsky       1\n",
       "1  toda su construcción intelectual. Si de algo n...  Chomsky       2\n",
       "2  tales como la ya lejana Guerra de Vietnam (la ...  Chomsky       3\n",
       "3  un sistema de financiación sin parangón, que d...  Chomsky       4\n",
       "4  de la lingüística y de las ciencias cognitivas...  Chomsky       5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos los datos \n",
    "ensayos= pd.read_csv('data/ensayos.csv', sep=',')\n",
    "ensayos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensayos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos entonces contienen 269 entradas donde fueron catalogadas como pertenecientes a alguno de estos 3 autores. De estas, 101 páginas se refieren a Voltaire, 85 a Freud, y 83 a Chomsky. En nuestra tarea no supervisada ignoraremos por ahora esta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Voltaire    101\n",
       "Freud        85\n",
       "Chomsky      83\n",
       "Name: titulo, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensayos.titulo.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder con el análisis de datos tenemos que \"limpiarlos\", para ello cargaremos las librerías que nos ayudarán en la tarea y la lista de *stopwords*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerías a utilizar\n",
    "import unidecode\n",
    "import regex\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Creamos una lista de stopwords\n",
    "from nltk.corpus import stopwords\n",
    "lista_stopwords = stopwords.words(\"spanish\")\n",
    "\n",
    "# Cargamos extra stop words\n",
    "extra_stopwords = pd.read_csv('data/stopword_extend.csv', sep=',')\n",
    "extra_stopwords=extra_stopwords['palabra'].to_list()\n",
    "lista_stopwords=lista_stopwords+extra_stopwords\n",
    "lista_stopwords=np.unique(lista_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos entonces  a crear una función que nos ayude con la limpieza del texto como lo hicimos en el *cuaderno: Sistemas de Recomendación basado en Contenidos*:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(txt):\n",
    "\n",
    "    out = unidecode.unidecode(txt)\n",
    "    out = out.split(\" \")\n",
    "    out = [regex.sub(\"[^\\\\w\\\\s]|\\n\", \"\", i) for i in out]\n",
    "    out = [regex.sub(\"^[0-9]*$\", \"\", i) for i in out]\n",
    "    out = [ i.lower() for i in out]\n",
    "    out = [i for i in out if i not in lista_stopwords]\n",
    "    out = ' '.join(out)\n",
    "    out = nlp(out)\n",
    "    out = [x.lemma_ for x in out]\n",
    "    out = [regex.sub(\"él\", \"\", i) for i in out]\n",
    "    out = [i for i in out if len(i) >= 2]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos esta función sobre las filas que contienen el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = list(map(text_cleaning, ensayos['texto']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así la fila 100 lucirá de la siguiente manera y podemos ver que se refiere a Freud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serio', 'candidatura', 'premio', 'nobel', 'freud', 'escribio', 'publico', 'magistral', 'libro', 'malestar', 'cultura', 'contribución', 'significativo', 'autor', 'pensamiento', 'contemporaneo', 'obstante', 'progresion', 'cancer', 'consecuent', 'dolor', 'seriar', 'unico', 'motivo', 'preocupacion', 'freud', 'ano', 'venidero', 'fruto', 'persecucion', 'nazi', 'freud', 'ver', 'obligado', 'abandonar', 'vién', 'refugiar ', 'bien', 'amado', 'londres', 'freud', 'llego', 'londres', 'recuperar ', 'largo', 'viaje', 'animos', 'reemprender', 'escrito', 'epocar', 'termino', 'ultimo', 'obra', 'moís', 'religion', 'monoteista', 'labor', 'terapeuto', 'poco', 'paciente', 'obstante', 'cancer', 'progreso', 'devino', 'inoperable', 'largo', 'agonia', 'soporto', 'estoicamente', 'murio', 'noche', 'septiembre', 'ceniza', 'reposar', 'golders', 'green', 'londres', 'freud', 'gestapo', 'estallido', 'segundo', 'guerra', 'mundial', 'adolf', 'hitler', 'promover', 'durisima', 'represalia', 'comunidad', 'judia', 'alemán', 'judio', 'austriaco', 'temiar', 'medida', 'extender', 'territorio', 'principio', 'freud', 'encontrar', 'respondio', 'ironia', 'noticia', 'libro', 'psicoanalista', 'habiar', 'quemado', 'publicamente', 'berlin', 'progresamos', 'exclamo', 'edad', 'medio', 'quemado', 'conformar', 'quemar', 'libro', 'dejar', 'ser', 'oportuno', 'mentar', 'palabra', 'premonitoria', 'heinrich', 'heinar', 'poeta', 'romantico', 'origen', 'judio', 'dejar', 'escrito', 'quemar', 'libro', 'acabar', 'quemar', 'ser', 'humano', 'efecto', 'nacionalismo', 'antisemitar', 'violento', 'extremo', 'extendio', 'polvoro', 'austrio', 'freud', 'termino', 'aceptar', 'necesidad', 'abandonar', 'viena', 'movio', 'cielo', 'tierrir', 'conseguir', 'salvoconducto', 'allegado', 'presidente', 'roosevelt', 'intercedio', 'favor', 'finalmente', 'nazi', 'acceder', 'reganadient', 'freud', 'obligado', 'firmar', 'carta', 'dejar', 'constancia', 'primero', 'persona', 'excelente', 'trato', 'recibido', 'parte', 'autoridad', 'nazi', 'circunstancia', 'luctuoso', 'freud', 'respondio', 'sarcasmo', 'pedir', 'anadir', 'ultima', 'line']\n"
     ]
    }
   ],
   "source": [
    "print(clean[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos tokenizados vamos a remover palabras que sean raras y demasiado comunes. En este caso removeremos palabras que aparecen en menos de 20 páginas o en más de 50% de las páginas. Para ello, primero utilizaremos la librería  [gensim](https://radimrehurek.com/gensim/index.html) que contiene múltiples  funciones que facilitan el modelado de tópicos. \n",
    "\n",
    "El primer paso es generar una representación de diccionario del documento, esto en términos de [gensim](https://radimrehurek.com/gensim/index.html), implica crear un mapeo entre palabras y un identificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7ff6008044f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos la función \n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Creamos la representación de diccionario del documento\n",
    "dictionary = Dictionary(clean)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora aprovechamos la función `filter_extremes` para remover palabras que aparecen en menos de 20 páginas o en más de 50% de las páginas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estamos en condiciones de vectorizar el documento. Para ello utilizamos la función `doc2bow` que va a crear la matriz de frecuencia de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos ver el número de palabras únicas con el que vamos a estimar LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palabras únicas: 337\n"
     ]
    }
   ],
   "source": [
    "print('Numero de palabras únicas: %d' % len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos listos para estimar LDA. Para ello utilizaremos la función [LDAModel](https://radimrehurek.com/gensim/models/ldamodel.html?highlight=ldamodel#module-gensim.models.ldamode) disponible en [gensim](https://radimrehurek.com/gensim/index.html). Carguemos entonces esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de ajustarla, discutiremos algunos de los parámetros:\n",
    "\n",
    "   - `corpus` es donde especificamos la matriz de frecuencia de los documentos.\n",
    "   \n",
    "   - `id2word` es donde especificamos el diccionario que mapea palabras con identificadores, este sirve para determinar el tamaño del vocabulario y para mostrar luego los tópicos con las palabras encontradas.\n",
    "   \n",
    "   - `num_topics` donde especificamos el número de tópicos a buscar.  \n",
    "   \n",
    "   - `chunksize` controla cuántos documentos se procesan a la vez en el entrenamiento. Aumentar el tamaño de los fragmentos acelerará el entrenamiento, siempre y cuando el fragmento de documentos entre fácilmente en la memoria.  \n",
    "   - `passes` controla la frecuencia con la que entrenamos el modelo en todo el corpus.\n",
    "   \n",
    "   - `iterations` controla la frecuencia con la que repetimos un bucle particular sobre cada documento. Cuando entrenamos  es importante establecer el número de \"passes\" e \"iterations\" lo suficientemente alto.\n",
    "   \n",
    "   - `alpha` es el parámetro que controla el \"prior\" de la distribución de tópicos. \n",
    "   \n",
    "   - `eta` es el parámetro que controla el \"prior\" de la distribución de palabras-tópicos.\n",
    "   \n",
    "Estimemos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimacion = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=3,\n",
    "    chunksize=1000,\n",
    "    passes=20,\n",
    "    iterations=400,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    random_state=123,\n",
    "    eval_every=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que elegimos 3 tópicos ya que tenemos la sospecha de que los textos se refieren a 3 escritores distintos. Vamos a fijar `chunksize = 1000`, que es más que la cantidad de documentos, así procesamos todos los datos de una sola vez. No obstante, el tamaño de los fragmentos puede influir en la calidad del modelo (Hoffman et al., 2010). Por eso, los invito a que prueben con distintos tamaños. Especificamos también 20 passes y 400 iteraciones. Es importante asignar estos parámetros lo suficientemente altos de forma tal que haya convergencia en la estimación. Nuevamente los invito a que prueben con distintos valores. Fijamos `alpha = 'auto'` y `eta = 'auto'` de forma que el modelo \"aprenda\" automáticamente estos 2 parámetros. Luego, establecemos el `random_state` para lograr reproducibilidad y finalmente fijamos `eval_every=None`. Esto evitará el cálculo de la perplejidad, que discutiremos más adelante, haciendo que el proceso sea más rapido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo estimado podemos utilizar `pprint` para ver los tópicos con las palabras asociadas y su peso dentro del tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.066*\"voltaire\" + 0.020*\"hombre\" + 0.019*\"hacer\" + 0.014*\"diccionario\" + '\n",
      "  '0.012*\"historia\" + 0.011*\"ano\" + 0.011*\"propio\" + 0.011*\"bien\" + '\n",
      "  '0.010*\"filosofico\" + 0.010*\"mundo\"'),\n",
      " (1,\n",
      "  '0.059*\"freud\" + 0.019*\"humano\" + 0.017*\"hombre\" + 0.013*\"primero\" + '\n",
      "  '0.011*\"parte\" + 0.011*\"sociedad\" + 0.010*\"vida\" + 0.009*\"caso\" + '\n",
      "  '0.009*\"manera\" + 0.009*\"gran\"'),\n",
      " (2,\n",
      "  '0.040*\"chomsky\" + 0.038*\"lenguaje\" + 0.028*\"linguistico\" + 0.018*\"frase\" + '\n",
      "  '0.018*\"generativo\" + 0.017*\"gramatico\" + 0.016*\"estructura\" + '\n",
      "  '0.016*\"teoria\" + 0.016*\"mente\" + 0.015*\"ejemplo\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(Estimacion.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos entonces que Voltaire tiene el mayor peso en el primer tópico, Freud en el segundo, y Chomsky en el tercero. El modelo parece haber hecho un gran trabajo encontrando los 3 autores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también generar una visualización interactiva de los resultados utilizando [pyLDAvis](https://pyldavis.readthedocs.io/en/latest/readme.html) que permite ayudar a la interpretación de los tópicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el60181406938246386408781339127\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el60181406938246386408781339127_data = {\"mdsDat\": {\"x\": [0.03318728274013761, -0.1660340259823587, 0.1328467432422211], \"y\": [-0.09533206078463746, 0.031787731847042686, 0.06354432893759475], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [34.77233541712576, 33.68934264563568, 31.538321937238557]}, \"tinfo\": {\"Term\": [\"voltaire\", \"freud\", \"lenguaje\", \"chomsky\", \"linguistico\", \"frase\", \"generativo\", \"gramatico\", \"diccionario\", \"estructura\", \"regla\", \"hombre\", \"rousseau\", \"gramatica\", \"rey\", \"sexual\", \"mente\", \"teoria\", \"psicoanalisis\", \"lengua\", \"inconsciente\", \"tolerancia\", \"fanatismo\", \"sexualidad\", \"sociedad\", \"deseo\", \"ley\", \"cognitiva\", \"historia\", \"hacer\", \"freud\", \"sexual\", \"psicoanalisis\", \"inconsciente\", \"sexualidad\", \"racional\", \"deseo\", \"consciente\", \"sentimiento\", \"podia\", \"impulso\", \"medico\", \"caracter\", \"cultura\", \"individuo\", \"desear\", \"afirmar\", \"origen\", \"fuerza\", \"sujeto\", \"amor\", \"oscuro\", \"tenia\", \"necesidad\", \"completo\", \"sociedad\", \"camino\", \"empezar\", \"social\", \"existencia\", \"politico\", \"madre\", \"persona\", \"manera\", \"gran\", \"humano\", \"parte\", \"hombre\", \"vida\", \"primero\", \"caso\", \"medio\", \"naturaleza\", \"considerar\", \"momento\", \"realidad\", \"bien\", \"mente\", \"dar\", \"ejemplo\", \"idea\", \"forma\", \"frase\", \"generativo\", \"gramatico\", \"linguistico\", \"gramatica\", \"lenguaje\", \"especifico\", \"sintaxi\", \"cognitiva\", \"cognitivo\", \"regla\", \"chomsky\", \"concepto\", \"lengua\", \"estructura\", \"lenguo\", \"disciplina\", \"simple\", \"hipotesis\", \"formal\", \"fundamental\", \"representacion\", \"consistir\", \"desarrollar\", \"nivel\", \"base\", \"facultad\", \"explicar\", \"poseer\", \"sistema\", \"mental\", \"teoria\", \"luis\", \"mente\", \"forma\", \"ciencia\", \"ejemplo\", \"estudio\", \"proceso\", \"aspecto\", \"idea\", \"pensamiento\", \"humano\", \"modo\", \"palabra\", \"deber\", \"posible\", \"primero\", \"voltaire\", \"diccionario\", \"rousseau\", \"rey\", \"tolerancia\", \"fanatismo\", \"hijo\", \"ley\", \"decidir\", \"mal\", \"carta\", \"mil\", \"escribir\", \"habrio\", \"paris\", \"comun\", \"espiritu\", \"pueblo\", \"tierra\", \"dios\", \"tratado\", \"vivir\", \"dejar\", \"antiguo\", \"amigo\", \"conciencia\", \"articulo\", \"casa\", \"servir\", \"celebrar\", \"historia\", \"describir\", \"mejor\", \"hacer\", \"parecer\", \"filosofo\", \"hombre\", \"filosofico\", \"propio\", \"ano\", \"saber\", \"religion\", \"obra\", \"mundo\", \"bien\", \"cosa\", \"escrito\", \"ver\", \"vida\", \"razon\", \"tiempo\", \"deber\", \"querer\"], \"Freq\": [369.0, 363.0, 231.0, 264.0, 168.0, 109.0, 107.0, 99.0, 77.0, 110.0, 80.0, 220.0, 56.0, 59.0, 54.0, 57.0, 141.0, 132.0, 51.0, 71.0, 48.0, 41.0, 41.0, 45.0, 93.0, 48.0, 43.0, 41.0, 90.0, 169.0, 362.0777924252142, 56.32047425834918, 50.50950513790239, 47.609496434657174, 44.71508094862857, 28.16804301625222, 46.22218678113423, 38.0493171003966, 39.59039442825881, 23.080845935946904, 34.02047751264568, 30.801311934673073, 40.451867239854806, 38.63017585703062, 19.427843924415004, 36.37923510850262, 19.73540789754195, 30.971115025003872, 36.87260896350349, 41.72652251426987, 26.05620849959498, 18.69265931669798, 26.562987183779768, 17.649426982676115, 20.679030013590054, 65.48321743885342, 21.077844434536665, 16.33373569904034, 33.0158509721757, 19.28729072667781, 53.14905712274619, 32.46440097382388, 33.62899524415574, 57.49432853773719, 56.70115079756957, 117.88695117426067, 66.46744047250662, 104.55392355670078, 59.869344820283146, 82.6879020731313, 57.75811427948707, 43.75063168392742, 46.72250778976085, 41.564711369931274, 37.02785079693516, 40.49024690026437, 46.612970613083306, 46.89065352452951, 40.81534048558912, 43.2216318404527, 42.26495697593595, 40.548303006501435, 108.53109185677864, 106.4745062872939, 98.46438104857361, 166.48331523995907, 58.39433070866506, 227.84836445725074, 32.377090016703164, 30.3928929490614, 39.9385546378595, 37.8725454177249, 76.20416516937345, 238.29030184960084, 31.32324688074329, 63.295416661886456, 97.16934182059836, 20.801982206701513, 23.196155223598005, 28.113742271983213, 22.91302971010673, 21.084584954404825, 27.719931849402407, 35.331418361898166, 18.226417781261905, 26.050614503592353, 26.026644929558607, 17.309565628034633, 28.123903618652154, 38.79430491345509, 19.861496047930384, 30.956459428124862, 45.774370779597824, 96.82484332627095, 39.70682102260024, 92.91565900304579, 81.55856809961764, 56.67555999664307, 92.2070437375525, 48.67897397583702, 49.796023239507534, 34.73591741042945, 74.84810239551847, 52.4883308332611, 86.02471291725413, 48.90233501860895, 45.14366286962415, 50.82395549612027, 44.81615357008219, 53.02778630033227, 368.31984483269196, 76.46335275252106, 55.926290643504494, 53.95497398430898, 40.34163389366227, 40.33963999506295, 34.298199933338, 40.33864304576329, 21.768857874300906, 38.554903435787814, 36.81200239998854, 25.21855428467448, 41.00136768893497, 30.30471441199785, 25.705244682236255, 19.7098862652882, 23.755263776542332, 28.400842411413244, 25.090186677454607, 38.61843039519771, 25.675305048580814, 30.03757613546503, 48.22367861877539, 27.22726692749582, 23.93132138815145, 23.822492948716075, 37.78308034607877, 18.960870987031033, 16.134274379500823, 22.574909556631642, 67.66946548553925, 22.673231085088556, 36.11449616888052, 104.8516398336917, 42.98426349885051, 54.75194667783525, 110.21043963225097, 57.542392190253146, 62.59244406012943, 63.48051299591221, 45.347573353250695, 42.505826491454414, 55.13866954210681, 56.16784315090149, 58.839890549096125, 42.44879527982512, 40.55499142867823, 49.46788692208493, 47.35206453888128, 40.28093681637901, 40.8566257087126, 40.24851000191869, 39.34421987023934], \"Total\": [369.0, 363.0, 231.0, 264.0, 168.0, 109.0, 107.0, 99.0, 77.0, 110.0, 80.0, 220.0, 56.0, 59.0, 54.0, 57.0, 141.0, 132.0, 51.0, 71.0, 48.0, 41.0, 41.0, 45.0, 93.0, 48.0, 43.0, 41.0, 90.0, 169.0, 363.3472565514108, 57.02635232722065, 51.22874019290942, 48.330504071198604, 45.43094065941628, 29.00781607931419, 48.34457609893118, 42.66757488059238, 44.50713606559052, 26.12835650983162, 38.81150338404492, 35.811365069449444, 47.45769299010185, 45.49335748662749, 23.293163761998695, 43.656701347416906, 24.284399660937556, 39.783088849249424, 48.470237880834055, 55.535972827063276, 34.88444852949864, 25.19771669681749, 35.85544346659706, 24.28816249206552, 29.23139256082029, 93.05454628636127, 30.054948416634744, 23.34988274629998, 47.51832485746985, 28.146909751518397, 77.70410605749085, 47.51199934974198, 49.620814922503904, 89.7001676635517, 93.42057455390768, 224.5773806902971, 115.9765716975496, 220.6896492393209, 109.76604879096175, 174.2963878723801, 119.21297131718124, 79.79696335419533, 89.89139604926794, 77.1142955980579, 63.383944492377516, 80.24023336438509, 133.00601269881528, 141.52935570932306, 94.87053830907894, 154.24094530061086, 145.9910484678629, 129.5852694929767, 109.22286806350799, 107.21639146174823, 99.1986510286851, 168.3137597001982, 59.10918532779998, 231.41274138407675, 33.05209800296682, 31.04828544978544, 41.05366738836356, 39.046870858150065, 80.07181590741095, 264.6207565431101, 34.95550537245437, 71.92284511552104, 110.77205400711082, 23.965047572841918, 26.924216268795707, 32.917934301735755, 26.935641460565233, 24.91601136865407, 33.883290943744974, 43.795918999312875, 22.90952005130754, 32.83480787169314, 32.836481689429846, 21.890989520629187, 35.830292414486465, 49.74836567168107, 25.85785234646792, 40.77321453827973, 60.58845516443714, 132.04344098664987, 52.7675066430557, 141.52935570932306, 129.5852694929767, 84.28034789042353, 154.24094530061086, 73.30452941483213, 76.25365619607487, 47.649915319715745, 145.9910484678629, 88.9457775697797, 224.5773806902971, 87.08688641327021, 86.82190230228474, 119.15583739593536, 85.84652870941981, 174.2963878723801, 369.0498922531144, 77.13333321111861, 56.63009960662247, 54.67787090979583, 41.00963073956862, 41.009592735562315, 35.14948782388825, 43.013388906872095, 23.46085211062249, 41.99195660431134, 40.97269792637147, 28.292469132462866, 45.9998440924294, 34.213081013009166, 29.26309391272401, 22.440227584122372, 27.310517795251645, 33.162464730958604, 29.300040871978993, 45.82271239165121, 31.372648015538026, 37.12348753466061, 61.42049843238646, 35.082372567054236, 31.232360786257583, 31.176523502817204, 49.952110500687716, 25.328941847056683, 21.561192465859328, 30.197769977705196, 90.97771858812693, 30.40792521827334, 50.749397612719946, 169.42255209895637, 62.29545707043803, 87.07680143991084, 220.6896492393209, 96.59742066555847, 119.25033912239527, 125.27788798388369, 74.25815323539501, 67.12098315801552, 105.66593157522223, 114.36869616354484, 133.00601269881528, 72.63730913378657, 68.18365479727898, 110.8031557124517, 109.76604879096175, 74.06143011515786, 81.17998610820418, 119.15583739593536, 74.42591558727857], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8319, -4.6927, -4.8016, -4.8607, -4.9234, -5.3855, -4.8903, -5.0848, -5.0451, -5.5847, -5.1968, -5.2962, -5.0236, -5.0697, -5.757, -5.1297, -5.7413, -5.2907, -5.1163, -4.9926, -5.4635, -5.7956, -5.4442, -5.853, -5.6946, -4.5419, -5.6755, -5.9305, -5.2267, -5.7643, -4.7506, -5.2436, -5.2083, -4.672, -4.6859, -3.954, -4.527, -4.074, -4.6316, -4.3087, -4.6675, -4.9452, -4.8795, -4.9965, -5.1121, -5.0227, -4.8818, -4.8759, -5.0147, -4.9574, -4.9798, -5.0212, -4.0051, -4.0242, -4.1024, -3.5772, -4.6249, -3.2634, -5.2146, -5.2779, -5.0047, -5.0579, -4.3587, -3.2186, -5.2477, -4.5443, -4.1156, -5.657, -5.5481, -5.3558, -5.5604, -5.6435, -5.3699, -5.1273, -5.7892, -5.432, -5.433, -5.8408, -5.3555, -5.0338, -5.7033, -5.2595, -4.8684, -4.1192, -5.0106, -4.1604, -4.2908, -4.6547, -4.1681, -4.8068, -4.7842, -5.1443, -4.3766, -4.7315, -4.2375, -4.8023, -4.8822, -4.7637, -4.8895, -4.7213, -2.7172, -4.2893, -4.6021, -4.638, -4.9287, -4.9288, -5.091, -4.9288, -5.5456, -4.974, -5.0203, -5.3985, -4.9125, -5.2148, -5.3794, -5.645, -5.4583, -5.2797, -5.4036, -4.9724, -5.3806, -5.2237, -4.7503, -5.3219, -5.4509, -5.4555, -4.9942, -5.6837, -5.8452, -5.5093, -4.4115, -5.5049, -5.0394, -3.9736, -4.8653, -4.6233, -3.9237, -4.5736, -4.4895, -4.4754, -4.8118, -4.8765, -4.6163, -4.5978, -4.5513, -4.8778, -4.9235, -4.7248, -4.7685, -4.9302, -4.916, -4.931, -4.9538], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0528, 1.0439, 1.0422, 1.0413, 1.0405, 1.027, 1.0115, 0.9418, 0.9393, 0.9323, 0.9246, 0.9056, 0.8966, 0.8928, 0.8749, 0.874, 0.8489, 0.806, 0.7829, 0.7705, 0.7646, 0.7577, 0.7564, 0.7371, 0.7102, 0.705, 0.7015, 0.699, 0.6922, 0.6784, 0.6765, 0.6755, 0.6673, 0.6116, 0.557, 0.4119, 0.4997, 0.3093, 0.4502, 0.3107, 0.3317, 0.4554, 0.402, 0.4383, 0.5188, 0.3724, 0.0078, -0.0483, 0.2129, -0.2158, -0.1832, -0.1055, 1.0816, 1.081, 1.0806, 1.0771, 1.0758, 1.0725, 1.0674, 1.0667, 1.0605, 1.0575, 1.0385, 0.9832, 0.9783, 0.9602, 0.957, 0.9464, 0.9389, 0.9302, 0.9262, 0.921, 0.8872, 0.8732, 0.8593, 0.8565, 0.8556, 0.8532, 0.8458, 0.8393, 0.8242, 0.8125, 0.8076, 0.7778, 0.8036, 0.6672, 0.625, 0.6912, 0.5735, 0.6786, 0.6619, 0.7719, 0.4199, 0.5606, 0.1284, 0.5109, 0.434, 0.2359, 0.438, -0.102, 1.152, 1.1452, 1.1415, 1.1407, 1.1375, 1.1375, 1.1294, 1.0898, 1.0791, 1.0686, 1.0469, 1.039, 1.0389, 1.0327, 1.0243, 1.0242, 1.0145, 0.999, 0.9989, 0.9829, 0.9536, 0.9422, 0.9121, 0.9005, 0.8877, 0.8849, 0.8748, 0.8644, 0.864, 0.863, 0.858, 0.8604, 0.8138, 0.6741, 0.7829, 0.69, 0.4596, 0.6359, 0.5094, 0.4742, 0.6608, 0.6971, 0.5035, 0.4429, 0.3384, 0.6168, 0.6344, 0.3475, 0.3132, 0.545, 0.4674, 0.0686, 0.5165]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 1, 3, 1, 2, 3, 1, 2, 3, 2, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 2, 3, 1, 2, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 3, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3], \"Freq\": [0.8235739931496356, 0.12353609897244534, 0.04117869965748178, 0.1600903637806345, 0.0640361455122538, 0.7684337461470455, 0.7453177876099758, 0.2293285500338387, 0.28736116627885044, 0.20753862009028087, 0.5028820409879883, 0.19953040481001225, 0.028504343544287464, 0.7696172756957615, 0.08007669665819085, 0.1601533933163817, 0.760728618252813, 0.23085035778539176, 0.734523865680792, 0.04197279232461668, 0.13704268585816648, 0.7765752198629433, 0.04568089528605549, 0.35336748351692104, 0.21051679869093168, 0.4435889686701775, 0.6987202143516895, 0.29945152043643836, 0.8428559729682333, 0.04214279864841167, 0.10535699662102917, 0.09762598516670926, 0.9030403627920607, 0.23688316852041028, 0.7501300336479658, 0.4865242377499646, 0.22648542102153527, 0.28520386350859994, 0.2318051963826485, 0.7616456452572736, 0.0982538193135438, 0.8994003460239779, 0.1898425955811464, 0.6763142467578341, 0.13051678446203815, 0.02435835976698746, 0.9743343906794983, 0.02561024681421494, 0.9731893789401679, 0.718405733025081, 0.20525878086430885, 0.06841959362143629, 0.08912565581175763, 0.8912565581175763, 0.05721559390115526, 0.8868417054679065, 0.02860779695057763, 0.2245279208044944, 0.769810014186838, 0.8906060423247664, 0.09374800445523856, 0.02343700111380964, 0.5446460954388561, 0.20748422683384996, 0.24638751936519682, 0.043649975982055805, 0.7856995676770046, 0.13094992794616742, 0.15143732788531192, 0.26157356634735696, 0.5782152519257364, 0.8572680091036109, 0.15386861701859683, 0.4321678861610968, 0.24243564345622504, 0.32676108465839027, 0.23498638935296623, 0.42801092346433134, 0.3356948419328089, 0.04262419776079765, 0.9377323507375483, 0.19537451349747614, 0.01628120945812301, 0.7814980539899046, 0.15227742521102114, 0.7918426110973099, 0.03045548504220423, 0.06577232697211843, 0.1973169809163553, 0.756381760179362, 0.8246156692763976, 0.09162396325293307, 0.06871797243969979, 0.9515028098677855, 0.04136968738555589, 0.985306829564637, 0.1527626723658415, 0.8511063174668313, 0.1114238561319574, 0.8542495636783402, 0.2787845984488381, 0.5964693734254211, 0.12318389233785869, 0.685228280323393, 0.1284803025606362, 0.17130707008084825, 0.10869602057679352, 0.891307368729707, 0.3519905184219866, 0.05866508640366443, 0.6013171356375604, 0.9681684956013266, 0.10984778913717982, 0.8787823130974386, 0.09930302456334225, 0.875672125694927, 0.027082643062729703, 0.2591927149887087, 0.6684443702340382, 0.06820860920755492, 0.6750296983836755, 0.03552787886229872, 0.248695152036091, 0.14070813996578593, 0.7839453512379502, 0.08040465140902053, 0.11163738084322106, 0.7814616659025474, 0.11163738084322106, 0.9753815468962991, 0.3002150554351175, 0.1035224329086612, 0.600430110870235, 0.20671406967585132, 0.16077760974788435, 0.6316263240095458, 0.31639398644937905, 0.6327879728987581, 0.0540184854913574, 0.12040450438123461, 0.8428315306686422, 0.9979595109755001, 0.996292096535425, 0.0027521881119763124, 0.7633550322357799, 0.04126243417490702, 0.2063121708745351, 0.08853921553785245, 0.8263660116866228, 0.11805228738380326, 0.9886547994652273, 0.9812349752132633, 0.9879166599922967, 0.6101439674523577, 0.11774708143817428, 0.27831128339932104, 0.058457173127422254, 0.058457173127422254, 0.8768575969113338, 0.18887686204437193, 0.19477926398325857, 0.6197522035830955, 0.028449916681869296, 0.9672971671835561, 0.07425106259036279, 0.853887219789172, 0.11137659388554418, 0.13190042777755545, 0.13190042777755545, 0.7474357574061475, 0.47578126279105915, 0.027187500730917667, 0.49843751340015724, 0.5254313664060746, 0.38294150432985097, 0.09350897198752176, 0.28768887161766965, 0.5137301278886959, 0.1986423161169624, 0.8760289356370852, 0.10306222772201003, 0.9931615844371969, 0.8156899678435818, 0.12879315281740764, 0.042931050939135885, 0.01390378812731643, 0.8759386520209351, 0.11123030501853144, 0.00432128323626008, 0.9852525778672981, 0.00864256647252016, 0.8762761657856244, 0.12518230939794633, 0.04649715009273466, 0.9299430018546933, 0.005941284906125369, 0.9862532944168112, 0.7580422601844515, 0.24636373455994673, 0.6735140688238325, 0.31570971976117146, 0.04762816886209724, 0.02381408443104862, 0.9287492928108962, 0.6354503172591179, 0.20066852123972145, 0.15607551651978335, 0.8656469793843742, 0.13962048054586682, 0.5513994286310984, 0.10025444156929061, 0.35089054549251714, 0.21675134124632317, 0.07881866954411752, 0.7093680258970577, 0.23106712263918897, 0.7592205458144781, 0.3320865820694465, 0.6571074921799687, 0.014131343917848788, 0.1060352840168973, 0.8836273668074776, 0.10334506572310512, 0.5626564689369057, 0.3330007673300054, 0.5837440426960108, 0.18932239222573324, 0.22087612426335543, 0.33225874976891223, 0.18361667750387256, 0.4896444733436602, 0.5228531546471934, 0.24473977451570755, 0.24473977451570755, 0.741101761233698, 0.12351696020561632, 0.1646892802741551, 0.15226966297091182, 0.7918022474487415, 0.06090786518836473, 0.2839136470267466, 0.1987395529187226, 0.5205083528823687, 0.7792255678654995, 0.07540892592246769, 0.15081785184493537, 0.7540365751631666, 0.23811681320942105, 0.28794577562880835, 0.518302396131855, 0.19580312742758968, 0.3049981634859269, 0.6902590015734135, 0.10251820976098353, 0.8884911512618572, 0.5690804533532738, 0.16382619111685157, 0.26729536445381047, 0.30355572504628425, 0.5846258408298808, 0.1124280463134386, 0.6851963244275621, 0.1410698314997922, 0.18137549764258998, 0.8802696790877576, 0.11481778422883794, 0.682074637867746, 0.07721599673974483, 0.24451732300919196, 0.15469188803479206, 0.7734594401739602, 0.07734594401739603, 0.2795686716842927, 0.5241912594080489, 0.19802780910970735, 0.47620034478725193, 0.3040797382376428, 0.22375678851449185, 0.2622825054915792, 0.655706263728948, 0.07868475164747377, 0.3102716543390641, 0.16771440775084545, 0.5283003844151632, 0.9955349244965216, 0.12061829639175842, 0.030154574097939604, 0.844328074742309, 0.2552874203840849, 0.2149788803234399, 0.5240110207883848, 0.965257085312504, 0.378064533137733, 0.08101382852951422, 0.5400921901967615, 0.4985030367291297, 0.28663924611924957, 0.1994012146916519, 0.9491479509829115, 0.03746636648616756, 0.3575632964657185, 0.6406342395010789, 0.15983224373279675, 0.7991612186639838, 0.022833177676113824, 0.9876024633271815, 0.9888734151802765, 0.2558641599902283, 0.13466534736327807, 0.6059940631347512, 0.8987322828647452, 0.11234153535809314, 0.09275924804098211, 0.18551849608196422, 0.7420739843278569, 0.9820021396190418, 0.9905143795580433, 0.06075715388661373, 0.8506001544125922, 0.06075715388661373, 0.9662369295244713, 0.12262952667874089, 0.7603030654081935, 0.12262952667874089, 0.6944689253878953, 0.021044512890542284, 0.29462318046759195, 0.6985150386953942, 0.29015240068885606, 0.7562665757343671, 0.21607616449553343, 0.018006347041294453, 0.7530237361351619, 0.25100791204505396, 0.22719795679236443, 0.7346067269619784, 0.037866326132060736, 0.30795767772955385, 0.19709291374691446, 0.5050505914764684, 0.10238893567104342, 0.06825929044736227, 0.8532411305920284, 0.9753806430011459, 0.15937449709452753, 0.8287473848915432, 0.27075041145807993, 0.2797754251733493, 0.44222567204819724, 0.5466171066634993, 0.02733085533317496, 0.42818340021974105, 0.10774849739710934, 0.08081137304783201, 0.80811373047832, 0.9971551481922819], \"Term\": [\"afirmar\", \"afirmar\", \"afirmar\", \"amigo\", \"amigo\", \"amigo\", \"amor\", \"amor\", \"ano\", \"ano\", \"ano\", \"antiguo\", \"antiguo\", \"antiguo\", \"articulo\", \"articulo\", \"articulo\", \"aspecto\", \"aspecto\", \"aspecto\", \"base\", \"base\", \"base\", \"bien\", \"bien\", \"bien\", \"camino\", \"camino\", \"caracter\", \"caracter\", \"caracter\", \"carta\", \"carta\", \"casa\", \"casa\", \"caso\", \"caso\", \"caso\", \"celebrar\", \"celebrar\", \"chomsky\", \"chomsky\", \"ciencia\", \"ciencia\", \"ciencia\", \"cognitiva\", \"cognitiva\", \"cognitivo\", \"cognitivo\", \"completo\", \"completo\", \"completo\", \"comun\", \"comun\", \"concepto\", \"concepto\", \"concepto\", \"conciencia\", \"conciencia\", \"consciente\", \"consciente\", \"consciente\", \"considerar\", \"considerar\", \"considerar\", \"consistir\", \"consistir\", \"consistir\", \"cosa\", \"cosa\", \"cosa\", \"cultura\", \"cultura\", \"dar\", \"dar\", \"dar\", \"deber\", \"deber\", \"deber\", \"decidir\", \"decidir\", \"dejar\", \"dejar\", \"dejar\", \"desarrollar\", \"desarrollar\", \"desarrollar\", \"describir\", \"describir\", \"describir\", \"desear\", \"desear\", \"desear\", \"deseo\", \"deseo\", \"diccionario\", \"dios\", \"dios\", \"disciplina\", \"disciplina\", \"ejemplo\", \"ejemplo\", \"ejemplo\", \"empezar\", \"empezar\", \"empezar\", \"escribir\", \"escribir\", \"escrito\", \"escrito\", \"escrito\", \"especifico\", \"espiritu\", \"espiritu\", \"estructura\", \"estructura\", \"estructura\", \"estudio\", \"estudio\", \"estudio\", \"existencia\", \"existencia\", \"existencia\", \"explicar\", \"explicar\", \"explicar\", \"facultad\", \"facultad\", \"facultad\", \"fanatismo\", \"filosofico\", \"filosofico\", \"filosofico\", \"filosofo\", \"filosofo\", \"filosofo\", \"forma\", \"forma\", \"forma\", \"formal\", \"formal\", \"frase\", \"freud\", \"freud\", \"fuerza\", \"fuerza\", \"fuerza\", \"fundamental\", \"fundamental\", \"fundamental\", \"generativo\", \"gramatica\", \"gramatico\", \"gran\", \"gran\", \"gran\", \"habrio\", \"habrio\", \"habrio\", \"hacer\", \"hacer\", \"hacer\", \"hijo\", \"hijo\", \"hipotesis\", \"hipotesis\", \"hipotesis\", \"historia\", \"historia\", \"historia\", \"hombre\", \"hombre\", \"hombre\", \"humano\", \"humano\", \"humano\", \"idea\", \"idea\", \"idea\", \"impulso\", \"impulso\", \"inconsciente\", \"individuo\", \"individuo\", \"individuo\", \"lengua\", \"lengua\", \"lengua\", \"lenguaje\", \"lenguaje\", \"lenguaje\", \"lenguo\", \"lenguo\", \"ley\", \"ley\", \"linguistico\", \"linguistico\", \"luis\", \"luis\", \"madre\", \"madre\", \"mal\", \"mal\", \"mal\", \"manera\", \"manera\", \"manera\", \"medico\", \"medico\", \"medio\", \"medio\", \"medio\", \"mejor\", \"mejor\", \"mejor\", \"mental\", \"mental\", \"mente\", \"mente\", \"mente\", \"mil\", \"mil\", \"modo\", \"modo\", \"modo\", \"momento\", \"momento\", \"momento\", \"mundo\", \"mundo\", \"mundo\", \"naturaleza\", \"naturaleza\", \"naturaleza\", \"necesidad\", \"necesidad\", \"necesidad\", \"nivel\", \"nivel\", \"nivel\", \"obra\", \"obra\", \"obra\", \"origen\", \"origen\", \"origen\", \"oscuro\", \"oscuro\", \"palabra\", \"palabra\", \"palabra\", \"parecer\", \"parecer\", \"paris\", \"paris\", \"parte\", \"parte\", \"parte\", \"pensamiento\", \"pensamiento\", \"pensamiento\", \"persona\", \"persona\", \"persona\", \"podia\", \"podia\", \"politico\", \"politico\", \"politico\", \"poseer\", \"poseer\", \"poseer\", \"posible\", \"posible\", \"posible\", \"primero\", \"primero\", \"primero\", \"proceso\", \"proceso\", \"proceso\", \"propio\", \"propio\", \"propio\", \"psicoanalisis\", \"pueblo\", \"pueblo\", \"pueblo\", \"querer\", \"querer\", \"querer\", \"racional\", \"razon\", \"razon\", \"razon\", \"realidad\", \"realidad\", \"realidad\", \"regla\", \"regla\", \"religion\", \"religion\", \"representacion\", \"representacion\", \"representacion\", \"rey\", \"rousseau\", \"saber\", \"saber\", \"saber\", \"sentimiento\", \"sentimiento\", \"servir\", \"servir\", \"servir\", \"sexual\", \"sexualidad\", \"simple\", \"simple\", \"simple\", \"sintaxi\", \"sistema\", \"sistema\", \"sistema\", \"social\", \"social\", \"social\", \"sociedad\", \"sociedad\", \"sujeto\", \"sujeto\", \"sujeto\", \"tenia\", \"tenia\", \"teoria\", \"teoria\", \"teoria\", \"tiempo\", \"tiempo\", \"tiempo\", \"tierra\", \"tierra\", \"tierra\", \"tolerancia\", \"tratado\", \"tratado\", \"ver\", \"ver\", \"ver\", \"vida\", \"vida\", \"vida\", \"vivir\", \"vivir\", \"vivir\", \"voltaire\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el60181406938246386408781339127\", ldavis_el60181406938246386408781339127_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el60181406938246386408781339127\", ldavis_el60181406938246386408781339127_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el60181406938246386408781339127\", ldavis_el60181406938246386408781339127_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.033187 -0.095332       1        1  34.772335\n",
       "2     -0.166034  0.031788       2        1  33.689343\n",
       "0      0.132847  0.063544       3        1  31.538322, topic_info=            Term        Freq       Total Category  logprob  loglift\n",
       "335     voltaire  369.000000  369.000000  Default  30.0000  30.0000\n",
       "311        freud  363.000000  363.000000  Default  29.0000  29.0000\n",
       "26      lenguaje  231.000000  231.000000  Default  28.0000  28.0000\n",
       "7        chomsky  264.000000  264.000000  Default  27.0000  27.0000\n",
       "28   linguistico  168.000000  168.000000  Default  26.0000  26.0000\n",
       "..           ...         ...         ...      ...      ...      ...\n",
       "121         vida   47.352065  109.766049   Topic3  -4.7685   0.3132\n",
       "244        razon   40.280937   74.061430   Topic3  -4.9302   0.5450\n",
       "78        tiempo   40.856626   81.179986   Topic3  -4.9160   0.4674\n",
       "59         deber   40.248510  119.155837   Topic3  -4.9310   0.0686\n",
       "231       querer   39.344220   74.425916   Topic3  -4.9538   0.5165\n",
       "\n",
       "[183 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "247       1  0.823574   afirmar\n",
       "247       2  0.123536   afirmar\n",
       "247       3  0.041179   afirmar\n",
       "102       1  0.160090     amigo\n",
       "102       2  0.064036     amigo\n",
       "...     ...       ...       ...\n",
       "121       3  0.428183      vida\n",
       "266       1  0.107748     vivir\n",
       "266       2  0.080811     vivir\n",
       "266       3  0.808114     vivir\n",
       "335       3  0.997155  voltaire\n",
       "\n",
       "[356 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos los resultados\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "LDA_visualization = gensimvis.prepare(Estimacion, corpus, dictionary)\n",
    "LDA_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos entonces una gráfica  interactiva donde cada burbuja en la gráfica del lado izquierdo representa un tema. Cuanto más grande es la burbuja, más frecuente es ese tema. Un buen modelo de tópicos tendrá burbujas bastante grandes que no se superpongan dispersas por todo el gráfico en lugar de estar agrupadas en un cuadrante. Un modelo con demasiados temas normalmente tendrá muchas superposiciones, burbujas de pequeño tamaño agrupadas en una región del gráfico.\n",
    "\n",
    "Cuando posamos el cursor sobre las burbujas, las palabras y las barras del lado derecho se actualizarán. Estas palabras son las palabras claves sobresalientes que forman el tema seleccionado. La gráfica de la derecha también contiene un parámetro $\\lambda$ que al deslizarlo cambia la distribución de frecuencia de las palabras. Los valores de $\\lambda$ que están muy cerca de cero mostrarán términos que son más específicos para un tema elegido. Lo que significa que verán términos que son \"importantes\" para ese tema específico, pero no necesariamente \"importantes\" para todo el corpus. Los valores de  $\\lambda$ que están muy cerca de uno mostrarán aquellos términos que tienen la relación más alta entre la frecuencia de los términos para ese tema específico y la frecuencia general de los términos del corpus. Utilizar diferentes valores del parámetro $\\lambda$ puede ayudar cuando estamos intentando asignar un  \"significado\" a cada tópico.\n",
    "\n",
    "El escenario ideal es como el descripto por la gráfica anterior, donde los círculos se distribuyen por todo el gráfico, alejados entre si y tienen un tamaño razonable y consistente. Es decir, los tópicos son distintos y  aparecen de manera uniforme en todo el corpus.\n",
    "\n",
    "[pyLDAvis](https://pyldavis.readthedocs.io/en/latest/readme.html) permite también guardar la visualización como html, que permite una mejor interacción, para ello podemos utilizar la función  `save_html`. Por ahora la dejamos escrita pero comentada y los invito a que la prueben por su cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.save_html(LDA_visualization, 'visualizacion_LDA.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligiendo el número de tópicos\n",
    "\n",
    "Elegir el número de tópicos,  como el número de clusters en K-medias, es un paso clave. La pregunta natural que surge es si existe algún método para hacerlo. Desafortunadamente, no existe una forma objetiva aceptada en la literatura de responderla. Sin embargo, hay 2 métodos  que pueden servir de guía.\n",
    "\n",
    "#### Medida de Coherencia\n",
    "\n",
    "Decimos que hechos, documentos o enunciados son coherentes, si se apoyan entre sí.  Un ejemplo de un conjunto de hechos coherente es \"el juego es un deporte de equipo\", “el juego se juega con una pelota”, “el juego exige un gran esfuerzo físico”. El problema fundamental es cómo medir esta coherencia en los datos. Röder et al. (2015) proponen una forma de hacerlo que consiste en 4 pasos que se muestran en la figura y describimos brevemente (los invito a leer el artículo original para los detalles matemáticos):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/coherencia.jpeg\" alt = \"coherencia\" style = \"width: 600px;\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzando con el tópico  que queremos evaluar (t), elegimos un corpus de referencia, y las n-palabras más importantes del tópico  que llamamos $W$:\n",
    "\n",
    "1. En el primer paso segmentamos el conjunto $W$ creando pares de palabras. Por ejemplo si tenemos las palabras W={perro, gato, conejo} y la segmentamos una a una vamos a tener: S={(perro,gato),(perro,conejo),(gato,perro),(gato,conejo),(conejo,perro),(conejo,gato)}. Existen múltiples formas de segmentar, pero la idea es que dependiendo la segmentación, la medida de coherencia va a estar interesada en estos conjuntos resultantes.\n",
    "\n",
    "2. Usando el corpus de referencia, en el segundo definimos y calculamos la probabilidad de ocurrencia de distintas palabras dentro del texto.  Al igual que en el paso anterior, se pueden definir distintas formas de calcular estas probabilidades.\n",
    "\n",
    "3. Con las palabras segmentadas y las probabilidades, utilizamos una medida de confirmación para evaluar la relación entre los subconjuntos creados en el paso de segmentación. Esto nos dice cuán fuerte es la relación de estos subconjuntos. Esto se pueden hacer por medidas de confirmación directa o indirecta, que están  más allá de este curso.\n",
    "\n",
    "4. Agregación, toma los valores calculados en el paso anterior y se los agrega en un solo resultado que da la medida de coherencia del tópico. Aquí también existen varias formas de hacer la agregación, por ejemplo, la media, la mediana, etc.\n",
    "\n",
    "\n",
    "[Gensim](https://radimrehurek.com/gensim/index.html) implementa esta medida a través de la función [CoherenceModel](https://radimrehurek.com/gensim/models/coherencemodel.html) que implementa los 4 pasos anteriores. La función requiere como insumos el modelo estimado, el corpus y el diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5144549459869845"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherencemodel = CoherenceModel(model=Estimacion, texts=clean, dictionary=dictionary)\n",
    "coherencemodel.get_coherence() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos una coherencia de 0.51, sin embargo, este número no tiene interpretación directa. Sirve sólo en un contexto donde se compara con otros modelos con diferentes números de tópicos, y escogeremos aquella con mayor coherencia.\n",
    "\n",
    "Ilustremos esto creando una función que itere a lo largo de distinto número de tópicos y devuelve la medida de coherencia. Adicionalmente, aprovecharemos que [Gensim](https://radimrehurek.com/gensim/index.html) tiene una implementación de LDA ([LdaMulticore](https://radimrehurek.com/gensim/models/ldamulticore.html)) que paraleliza y acelera la estimación del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "def calcular_coherencia(dictionary, corpus, texts, start=1, limit=10, step=1):\n",
    " \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=num_topics, \n",
    "                        random_state=123,\n",
    "                        passes=20)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función además de los insumos esenciales para la estimación de LDA, tiene además un punto de inicio, finalización y tamaño de paso para el rango de tópicos a estimar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos, valores_c = calcular_coherencia(dictionary=dictionary, corpus=corpus, texts=clean, start=1, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Show graph\n",
    "limit=10; start=1; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, valores_c)\n",
    "plt.xlabel(\"Número de Tópicos\")\n",
    "plt.ylabel(\"Medida de Coherencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La medida de coherencia sugiere que hay 4 tipos de tópicos en estas páginas, visualicemos entonces los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el60181406938292344641688428898\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el60181406938292344641688428898_data = {\"mdsDat\": {\"x\": [-0.011084607557739446, -0.0024942876436605294, 0.021288422810123022, -0.007709527608723061], \"y\": [0.0068433739041120056, -0.012496954712169493, 0.0030440617501885443, 0.002609519057868935], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [34.78691630025555, 33.00193285340116, 16.79509188522877, 15.416058961114526]}, \"tinfo\": {\"Term\": [\"frase\", \"chomsky\", \"freud\", \"estructura\", \"deber\", \"forma\", \"parte\", \"madre\", \"generativo\", \"voltaire\", \"luis\", \"sociedad\", \"religioso\", \"regla\", \"humano\", \"gramatico\", \"politico\", \"posible\", \"ano\", \"hombre\", \"primero\", \"orden\", \"sujeto\", \"vida\", \"considerar\", \"principio\", \"padre\", \"complejo\", \"ejemplo\", \"nino\", \"comun\", \"paris\", \"universal\", \"joven\", \"nunca\", \"recibir\", \"voltaire\", \"espiritu\", \"cultural\", \"conocido\", \"justo\", \"cultura\", \"seriar\", \"libro\", \"poco\", \"mucho\", \"serio\", \"amor\", \"cosa\", \"interno\", \"habrio\", \"dudar\", \"social\", \"pronto\", \"intelectual\", \"propio\", \"principio\", \"antiguo\", \"grande\", \"dado\", \"ano\", \"punto\", \"razon\", \"freud\", \"idea\", \"ver\", \"obra\", \"caso\", \"bien\", \"hacer\", \"mente\", \"vida\", \"hombre\", \"lenguaje\", \"parte\", \"momento\", \"manera\", \"realidad\", \"sociedad\", \"mundo\", \"dar\", \"primero\", \"linguistico\", \"tiempo\", \"teoria\", \"chomsky\", \"humano\", \"ejemplo\", \"cerebro\", \"hipotesis\", \"desarrollar\", \"linguistico\", \"medio\", \"numero\", \"actividad\", \"capacidad\", \"disciplina\", \"facultad\", \"historia\", \"humano\", \"campo\", \"seguir\", \"hecho\", \"sistema\", \"cognitivo\", \"lenguo\", \"chomsky\", \"comprender\", \"problema\", \"cientifico\", \"explicar\", \"escrito\", \"lengua\", \"ejemplo\", \"deber\", \"teoria\", \"tipo\", \"racional\", \"posibilidad\", \"lenguaje\", \"pensamiento\", \"filosofico\", \"mente\", \"hacer\", \"diccionario\", \"primero\", \"freud\", \"hombre\", \"generativo\", \"ciencia\", \"considerar\", \"idea\", \"caso\", \"voltaire\", \"regla\", \"forma\", \"naturaleza\", \"mundo\", \"gran\", \"bien\", \"propio\", \"filosofo\", \"frase\", \"frase\", \"madre\", \"luis\", \"nivel\", \"sujeto\", \"inconsciente\", \"estructura\", \"elemento\", \"deseo\", \"regla\", \"acabar\", \"producir\", \"representacion\", \"capaz\", \"interior\", \"placer\", \"generativo\", \"parte\", \"formar\", \"camino\", \"significado\", \"importante\", \"casa\", \"sintaxi\", \"consistir\", \"tener\", \"gramatico\", \"rey\", \"contar\", \"deber\", \"forma\", \"posible\", \"especie\", \"objeto\", \"termino\", \"padre\", \"hombre\", \"saber\", \"modo\", \"humano\", \"primero\", \"ver\", \"querer\", \"dar\", \"lenguaje\", \"ejemplo\", \"voltaire\", \"bien\", \"hacer\", \"freud\", \"chomsky\", \"vida\", \"ano\", \"sociedad\", \"linguistico\", \"religioso\", \"orden\", \"medico\", \"cuestion\", \"sentimiento\", \"unico\", \"dicho\", \"tierra\", \"celebrar\", \"cambio\", \"complejo\", \"religion\", \"cognitivo\", \"ciudad\", \"politico\", \"publico\", \"absoluto\", \"afirmar\", \"vivir\", \"sexual\", \"sociedad\", \"puesto\", \"efecto\", \"natural\", \"historico\", \"ley\", \"buen\", \"logico\", \"habiar\", \"existencia\", \"psicoanalisis\", \"filosofia\", \"chomsky\", \"freud\", \"nino\", \"filosofo\", \"obra\", \"considerar\", \"ano\", \"nuevo\", \"pensamiento\", \"idea\", \"voltaire\", \"vida\", \"primero\", \"forma\", \"gran\", \"lenguaje\", \"mundo\", \"bien\", \"hombre\", \"humano\", \"ejemplo\", \"mente\", \"estructura\", \"teoria\", \"hacer\", \"ver\", \"propio\"], \"Freq\": [109.0, 246.0, 368.0, 108.0, 116.0, 125.0, 121.0, 48.0, 105.0, 384.0, 52.0, 93.0, 60.0, 77.0, 220.0, 97.0, 74.0, 83.0, 127.0, 226.0, 172.0, 43.0, 56.0, 111.0, 73.0, 79.0, 67.0, 51.0, 149.0, 54.0, 14.46221684397084, 17.886547930366042, 19.15685374720765, 16.541061406323767, 20.26292378903361, 11.617297813703939, 196.23778816131005, 14.428123716975291, 12.596915730160312, 16.92116734154313, 14.965061472748319, 23.957521406540433, 14.41820261845141, 32.621436767350666, 15.653166759024435, 24.69767917019239, 23.833393845098325, 17.8326283563709, 35.884139427613476, 14.44428326639664, 16.625941279551398, 12.673363600327306, 23.41885114546882, 12.978237282733803, 30.838872088394233, 56.33974357865586, 36.1748566803612, 16.580397867537016, 25.58257987651706, 11.81591665978369, 57.519382095479024, 35.35652140488879, 34.98247780639191, 154.04723494655724, 60.66784536090471, 47.78983279378278, 44.384357378690936, 50.06748448688221, 54.26302240916063, 67.04096203386212, 55.84006041409266, 45.476093444860595, 80.48166368551333, 75.83816002956831, 46.0052635632412, 28.66383625458324, 36.56745956289135, 33.659599760584896, 36.107664111227315, 41.11038054758428, 36.55621975578896, 52.590132474717436, 49.40910956425884, 31.99955041086709, 40.39743313987804, 55.66544678915624, 52.45445296885468, 38.05856244136844, 17.37057194058152, 13.663985217184331, 15.399195594507873, 83.41409943991268, 38.93355370402582, 10.835304752401038, 18.628060435713085, 16.299733372403416, 12.483958160054993, 16.65528226934662, 42.781773177705624, 104.4822630903458, 26.21933161899233, 26.552546475960217, 18.65213045081847, 18.688439226426077, 16.53063300658447, 10.955671807340408, 114.09048064603928, 14.385050605362123, 16.428073280258193, 22.244922510251875, 21.794966721669894, 29.776947769217557, 31.077117073865274, 65.58515671393326, 50.65545545751504, 55.92248006988736, 26.746378015208386, 11.99754010197675, 16.052259114953973, 88.54854879978582, 34.485759934212545, 38.46959465439861, 53.46168778067127, 62.98305767915382, 32.12464630461627, 61.565029518375546, 113.83531675227428, 74.02233815098401, 40.158991860195115, 32.606685032632456, 29.957687502281434, 48.96094812774413, 42.89890395662984, 95.6439817469532, 30.514965402796882, 42.24421856270542, 33.391459893071676, 37.96856071807354, 32.382757824384576, 37.3202731667646, 35.18881356165121, 31.157588622108673, 31.397998085621147, 44.73863476581599, 19.833882056627353, 21.132034820729455, 10.628431937714707, 17.965110034140526, 15.064254406917048, 33.397213909210976, 9.807819989130438, 15.252414629752758, 23.319734238662814, 7.725854325425341, 10.796157154314896, 13.150659617801518, 11.801372676532148, 6.418140431075833, 10.000932560826852, 30.73799059989205, 34.73365128869604, 14.937705440999135, 8.654377568566069, 8.287097026028572, 10.904887618804345, 7.0327259568935006, 8.308541996206792, 6.2126151882260405, 15.962400616838078, 26.431308023956856, 15.003808652536819, 9.377107351191182, 31.191991858820735, 32.22993615781214, 21.675548886647928, 13.03659245130137, 14.151649329216777, 15.144141794373553, 16.636314093000834, 43.46393722182049, 17.563318588172972, 19.320260434795223, 36.31403678294263, 30.677555906034126, 22.365795989120105, 17.245527661392966, 19.88147963178856, 30.97979573845757, 24.36097180816963, 38.634603490158895, 22.581375246742383, 25.11535473177503, 32.98632933134592, 26.48330630442896, 19.637281272709956, 19.43327823424197, 17.674677309274426, 18.879581574979255, 19.26704752475813, 13.601509144740731, 9.885003201523267, 7.175890912875054, 11.57799715916363, 10.70277695920278, 13.085619978709367, 7.337796795742349, 7.574889719330746, 10.511435604336462, 12.968964392245136, 16.502388552465465, 8.739474758880839, 7.1824531386007235, 18.101609687743785, 5.720262088727971, 5.267354299710591, 5.690154658012698, 8.461255931387624, 13.167527875636841, 21.904501349097973, 5.8324842705175515, 8.235713844882008, 9.547007332726245, 6.218991878400864, 9.761137542450177, 11.782301796912893, 4.980025323710675, 5.787358340411358, 6.201508261339838, 11.143397865706923, 14.652556638555266, 50.24633928093203, 67.4691881363857, 11.664080210343172, 17.16369237659037, 20.876107556971498, 15.064747155786117, 23.724518346899313, 16.810083461360758, 16.841596358135046, 25.43725545416782, 54.31080245261266, 20.38565002960624, 27.796022173835418, 21.485082358122504, 16.948725232450254, 30.802463186726023, 18.94934620514017, 21.069223035133984, 28.07635649741927, 27.161155071102346, 21.74571350695935, 20.149625640935852, 16.253748598925824, 17.14401077558874, 18.310744306369457, 15.549403883733072, 15.514745027265505], \"Total\": [109.0, 246.0, 368.0, 108.0, 116.0, 125.0, 121.0, 48.0, 105.0, 384.0, 52.0, 93.0, 60.0, 77.0, 220.0, 97.0, 74.0, 83.0, 127.0, 226.0, 172.0, 43.0, 56.0, 111.0, 73.0, 79.0, 67.0, 51.0, 149.0, 54.0, 23.779698455558904, 30.648158176108332, 34.78168201654986, 30.049650327097496, 38.80092112272386, 22.474406496767813, 384.82717585103484, 28.361071490573707, 24.775132442354234, 33.482805904682024, 29.828582678641933, 47.98661592180054, 29.199679507172583, 66.071535082986, 31.992320553014775, 50.92064875124978, 49.55295697588253, 37.207616447004334, 74.91317070634926, 30.498499984335744, 35.297253330525635, 27.037594942790253, 49.99733297923778, 27.822846305359214, 67.2029460813448, 123.62620776350781, 79.49366794848088, 36.49899866181004, 56.33922790249355, 26.09265428732676, 127.49978202860372, 78.25829017213927, 77.96602046448997, 368.3380691665632, 144.88566014000364, 114.04732875109896, 105.74251370766967, 122.4488035573786, 135.2338938578016, 173.45011875116043, 140.81265247753268, 111.76435834876274, 226.0442955557371, 226.1689677545377, 121.14943846723942, 65.59370461105034, 91.34935358160423, 82.9478308894238, 93.18313028004596, 114.34809365760584, 96.76602212246723, 172.6287400729625, 165.13248260858998, 82.76137336667367, 129.33195346078128, 246.48557302055653, 220.41190791324544, 149.75040447043068, 32.20194436422439, 26.052150558444595, 30.4467942922805, 165.13248260858998, 78.7501450654746, 21.974585475302604, 37.94737936214663, 33.67979007691494, 25.818344369720307, 34.51083252286672, 89.5271172210365, 220.41190791324544, 55.822859686404335, 56.54916249663721, 39.78446377860379, 40.0544764362492, 35.67118706319706, 23.643207890181518, 246.48557302055653, 31.91108923860458, 36.659532810254646, 49.772574216137045, 48.95101724942707, 67.74018937892876, 70.83964269467108, 149.75040447043068, 116.24137087318441, 129.33195346078128, 62.32321106965063, 28.200574685110897, 37.86219698959179, 226.1689677545377, 85.3619682844701, 96.63973991572126, 140.81265247753268, 173.45011875116043, 79.10837643329454, 172.6287400729625, 368.3380691665632, 226.0442955557371, 105.10776804903894, 82.14630337145677, 73.84440816462161, 144.88566014000364, 122.4488035573786, 384.82717585103484, 77.68977690910029, 125.93532439198395, 89.15821035253789, 114.34809365760584, 92.70593349812445, 135.2338938578016, 123.62620776350781, 84.48479065457713, 109.17555170509011, 109.17555170509011, 48.646611872407725, 52.67757991070526, 33.100624771886096, 56.45944953081375, 48.77029518270903, 108.67149226646724, 31.953652970404846, 50.478414998854525, 77.68977690910029, 25.878310043366994, 36.330674710685635, 44.30629638092808, 39.87143084915421, 21.76040079927151, 34.15987679273229, 105.10776804903894, 121.14943846723942, 52.42798909743267, 30.576860459470833, 29.317581027503042, 39.13624458109969, 25.492485472326972, 30.12478127967986, 22.53487918327982, 58.12095579647017, 97.25932828103967, 55.65375914969627, 34.90319049676552, 116.24137087318441, 125.93532439198395, 83.95676442440646, 49.6537659673673, 54.35613695226954, 59.92560774543865, 67.56580688328631, 226.0442955557371, 74.91034322446752, 88.50901659236916, 220.41190791324544, 172.6287400729625, 114.04732875109896, 76.39909725845388, 96.76602212246723, 226.1689677545377, 149.75040447043068, 384.82717585103484, 135.2338938578016, 173.45011875116043, 368.3380691665632, 246.48557302055653, 111.76435834876274, 127.49978202860372, 93.18313028004596, 165.13248260858998, 60.07646647455644, 43.13225851886804, 35.39284827044978, 26.092631145077625, 42.27481193527675, 40.45312425253397, 49.83823038954947, 28.101919764756982, 29.198141567743825, 40.65423405500267, 51.755699461004916, 65.97332457557128, 35.67118706319706, 29.481615920048828, 74.73068572259135, 23.88234764055438, 22.132165988589076, 23.94592356393652, 35.886764683325495, 55.86283693076307, 93.18313028004596, 25.24139631522023, 35.670317785414845, 41.84601153832347, 27.32243258898588, 43.06295798908946, 52.19834882457819, 22.25454634366722, 25.99613338806976, 28.1911015523768, 50.70488872747928, 68.2678067870785, 246.48557302055653, 368.3380691665632, 54.647158474921, 84.48479065457713, 105.74251370766967, 73.84440816462161, 127.49978202860372, 84.4552184755957, 85.3619682844701, 144.88566014000364, 384.82717585103484, 111.76435834876274, 172.6287400729625, 125.93532439198395, 92.70593349812445, 226.1689677545377, 114.34809365760584, 135.2338938578016, 226.0442955557371, 220.41190791324544, 149.75040447043068, 140.81265247753268, 108.67149226646724, 129.33195346078128, 173.45011875116043, 114.04732875109896, 123.62620776350781], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.0526, -5.8401, -5.7715, -5.9183, -5.7154, -6.2717, -3.4448, -6.055, -6.1907, -5.8956, -6.0184, -5.5479, -6.0557, -5.2392, -5.9735, -5.5174, -5.5531, -5.8431, -5.1439, -6.0538, -5.9132, -6.1846, -5.5706, -6.1609, -5.2954, -4.6927, -5.1358, -5.9159, -5.4822, -6.2547, -4.672, -5.1587, -5.1693, -3.6869, -4.6187, -4.8573, -4.9313, -4.8108, -4.7303, -4.5188, -4.7017, -4.907, -4.3361, -4.3955, -4.8954, -5.3685, -5.125, -5.2078, -5.1376, -5.0079, -5.1253, -4.7616, -4.824, -5.2584, -5.0254, -4.7048, -4.7642, -5.085, -5.8167, -6.0567, -5.9372, -4.2477, -5.0096, -6.2887, -5.7468, -5.8803, -6.147, -5.8587, -4.9154, -4.0225, -5.405, -5.3923, -5.7455, -5.7436, -5.8663, -6.2776, -3.9345, -6.0053, -5.8725, -5.5694, -5.5898, -5.2777, -5.235, -4.4881, -4.7464, -4.6475, -5.3851, -6.1868, -5.8956, -4.1879, -5.1309, -5.0216, -4.6925, -4.5286, -5.2018, -4.5514, -3.9367, -4.3671, -4.9786, -5.187, -5.2717, -4.7804, -4.9126, -4.1108, -5.2533, -4.928, -5.1632, -5.0347, -5.1938, -5.0519, -5.1107, -5.2324, -5.2247, -4.1952, -5.0086, -4.9452, -5.6325, -5.1076, -5.2837, -4.4875, -5.7128, -5.2713, -4.8467, -5.9514, -5.6168, -5.4195, -5.5278, -6.1369, -5.6933, -4.5705, -4.4483, -5.2921, -5.8379, -5.8813, -5.6068, -6.0454, -5.8787, -6.1694, -5.2258, -4.7214, -5.2877, -5.7577, -4.5558, -4.5231, -4.9198, -5.4282, -5.3462, -5.2784, -5.1844, -4.2241, -5.1302, -5.0348, -4.4038, -4.5725, -4.8885, -5.1484, -5.0062, -4.5627, -4.803, -4.3418, -4.8789, -4.7725, -4.4999, -4.7195, -5.0186, -5.029, -5.1239, -5.0579, -4.9519, -5.3001, -5.6193, -5.9396, -5.4612, -5.5398, -5.3388, -5.9173, -5.8855, -5.5579, -5.3478, -5.1068, -5.7425, -5.9387, -5.0143, -6.1663, -6.2488, -6.1716, -5.7748, -5.3326, -4.8236, -6.1469, -5.8018, -5.6541, -6.0827, -5.6319, -5.4437, -6.3049, -6.1546, -6.0855, -5.4995, -5.2257, -3.9934, -3.6986, -5.4538, -5.0675, -4.8717, -5.198, -4.7438, -5.0883, -5.0865, -4.6741, -3.9156, -4.8955, -4.5854, -4.843, -5.0801, -4.4827, -4.9685, -4.8625, -4.5754, -4.6085, -4.8309, -4.9071, -5.122, -5.0687, -5.0028, -5.1663, -5.1685], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5586, 0.5174, 0.4595, 0.4589, 0.4063, 0.396, 0.3825, 0.3801, 0.3795, 0.3735, 0.3662, 0.3613, 0.3503, 0.3502, 0.3411, 0.3324, 0.324, 0.3204, 0.3199, 0.3086, 0.3031, 0.2982, 0.2975, 0.2933, 0.277, 0.2701, 0.2686, 0.2669, 0.2664, 0.2637, 0.2599, 0.2614, 0.2545, 0.1842, 0.1854, 0.1861, 0.1878, 0.1616, 0.1428, 0.1053, 0.131, 0.1567, 0.0232, -0.0368, 0.0877, 0.2281, 0.1404, 0.154, 0.1079, 0.0329, 0.0825, -0.1327, -0.1507, 0.1057, -0.1077, -0.432, -0.3796, -0.3139, 0.4914, 0.4633, 0.4269, 0.4257, 0.4042, 0.4015, 0.3971, 0.3829, 0.382, 0.3801, 0.3702, 0.3621, 0.3529, 0.3526, 0.3511, 0.3463, 0.3395, 0.3394, 0.3383, 0.3118, 0.3059, 0.3033, 0.2995, 0.2867, 0.2847, 0.283, 0.278, 0.2702, 0.2627, 0.254, 0.2505, 0.1709, 0.2022, 0.1875, 0.1401, 0.0956, 0.2074, 0.0776, -0.0656, -0.0078, 0.1465, 0.1846, 0.2064, 0.0237, 0.0598, -0.2836, 0.1741, 0.0163, 0.1265, 0.0061, 0.0568, -0.1789, -0.1479, 0.1111, -0.1376, 0.892, 0.8869, 0.8707, 0.6481, 0.639, 0.6093, 0.6042, 0.603, 0.5873, 0.5807, 0.5753, 0.5706, 0.5694, 0.5666, 0.5631, 0.5557, 0.5546, 0.5348, 0.5285, 0.5219, 0.5206, 0.5062, 0.4963, 0.496, 0.4956, 0.4918, 0.4813, 0.4732, 0.4698, 0.4686, 0.4212, 0.43, 0.4468, 0.4384, 0.4086, 0.3826, 0.1353, 0.3336, 0.2621, -0.0192, 0.0565, 0.155, 0.2957, 0.2016, -0.2039, -0.0319, -0.5146, -0.0058, -0.1483, -0.6288, -0.4467, 0.0451, -0.097, 0.1216, -0.3846, 0.7325, 0.7157, 0.5943, 0.5788, 0.5747, 0.5401, 0.5325, 0.527, 0.5205, 0.5171, 0.4858, 0.484, 0.4633, 0.4576, 0.4519, 0.4406, 0.4343, 0.4327, 0.4249, 0.4246, 0.4219, 0.4047, 0.4039, 0.392, 0.3897, 0.3855, 0.3813, 0.3726, 0.3675, 0.3555, 0.3546, 0.3309, 0.2794, 0.1724, 0.3254, 0.276, 0.2474, 0.2802, 0.1882, 0.2555, 0.2467, 0.13, -0.0883, 0.1682, 0.0435, 0.1014, 0.1705, -0.1239, 0.0723, 0.0106, -0.216, -0.2239, -0.0598, -0.0745, -0.0302, -0.151, -0.3786, -0.1228, -0.2057]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.3614648473233324, 0.22591552957708275, 0.1807324236616662, 0.22591552957708275, 0.309139197520764, 0.231854398140573, 0.309139197520764, 0.154569598760382, 0.23717052801221114, 0.500693336914668, 0.13176140445122841, 0.1581136853414741, 0.37584685242854216, 0.2505645682856948, 0.1252822841428474, 0.2505645682856948, 0.48377191873168807, 0.322514612487792, 0.10750487082926401, 0.080628653121948, 0.4549027384767457, 0.21176506791158853, 0.1490198626044512, 0.18823561592141203, 0.46576620245167416, 0.21918409527137608, 0.16438807145353204, 0.13699005954461005, 0.39930817977319344, 0.27360004910385477, 0.1700757061996935, 0.15528651435624188, 0.34483849403919253, 0.21073463524617322, 0.21073463524617322, 0.22989232935946172, 0.2459768393734984, 0.36896525906024763, 0.1229884196867492, 0.27057452331084825, 0.32704469490106247, 0.22893128643074376, 0.2943402254109562, 0.16352234745053124, 0.21496569805653654, 0.4657590124558292, 0.14331046537102435, 0.1612242735424024, 0.2969139646406014, 0.47506234342496223, 0.08907418939218041, 0.1484569823203007, 0.3009673780055615, 0.3009673780055615, 0.3009673780055615, 0.12540307416898394, 0.31381796838461645, 0.1961362302403853, 0.2745907223365394, 0.1961362302403853, 0.40833392036019667, 0.35116717150976917, 0.13066685451526294, 0.11433349770085507, 0.376736306126828, 0.3082387959219502, 0.06849751020487782, 0.2739900408195113, 0.2794862290986004, 0.5279184327418007, 0.09316207636620012, 0.09316207636620012, 0.22719382442448136, 0.4625017140069799, 0.10548284705422349, 0.2028516289504298, 0.32868186262635457, 0.40172227654332227, 0.10956062087545153, 0.15825423015343, 0.24109663180951996, 0.4420104916507866, 0.12054831590475998, 0.20091385984126664, 0.2713555465105846, 0.2374361031967615, 0.2374361031967615, 0.2374361031967615, 0.2242706413393744, 0.4765751128461706, 0.0560676603348436, 0.2523044715067962, 0.19321543528813578, 0.3477877835186444, 0.21253697881694938, 0.25118006587457653, 0.2506965506624564, 0.4387189636592987, 0.15668534416403526, 0.1253482753312282, 0.5887374907702947, 0.16821071164865561, 0.042052677912163904, 0.16821071164865561, 0.5077232788791702, 0.1791964513691189, 0.14933037614093242, 0.1791964513691189, 0.20312980187423865, 0.4062596037484773, 0.18958781508262276, 0.20312980187423865, 0.26625392358224015, 0.31062957751261355, 0.26625392358224015, 0.13312696179112007, 0.37245878714740166, 0.2865067593441551, 0.2578560834097396, 0.08595202780324654, 0.48055635158089527, 0.2803245384221889, 0.10679030035131006, 0.13348787543913757, 0.34492496942754086, 0.30659997282448076, 0.07664999320612019, 0.26827497622142066, 0.5001394563665551, 0.2709088721985507, 0.10419572007636564, 0.12503486409163878, 0.5247196974727731, 0.2018152682587589, 0.16145221460700712, 0.12108916095525533, 0.4598995513395668, 0.3065997008930445, 0.1149748878348917, 0.15329985044652225, 0.38236561954745585, 0.2686893542765906, 0.20668411867430045, 0.14467888307201032, 0.1720557822895891, 0.4387422448384522, 0.2666864625488631, 0.12043904760271237, 0.1642209012877163, 0.49266270386314887, 0.13137672103017303, 0.19706508154525956, 0.3565880584881372, 0.21791492463163942, 0.297156715406781, 0.1386731338564978, 0.36658570568002075, 0.4045083648882987, 0.1390497504303527, 0.08848620481931535, 0.30097376818470134, 0.26084393242674114, 0.1805842609108208, 0.26084393242674114, 0.27112505355725225, 0.4647858060981467, 0.11619645152453667, 0.15492860203271555, 0.4808119963150248, 0.2958843054246306, 0.07397107635615766, 0.1479421527123153, 0.3924831868395753, 0.2523106201111555, 0.1121380533827358, 0.2242761067654716, 0.25375557504756774, 0.44073336718788086, 0.16026667897741123, 0.1469111223959603, 0.15647663209683568, 0.4068392434517728, 0.31295326419367137, 0.09388597925810141, 0.3395325612590385, 0.4428685581639633, 0.07381142636066054, 0.14762285272132109, 0.3625102678380868, 0.261812971216396, 0.261812971216396, 0.10069729662169079, 0.49363438206674043, 0.28207678975242306, 0.07051919743810577, 0.14103839487621153, 0.2576572697772731, 0.2852634058248381, 0.30366749652321473, 0.14723272558701322, 0.3901940468542134, 0.21283311646593456, 0.1773609303882788, 0.21283311646593456, 0.26557160056060236, 0.4494288624871732, 0.18385726192657084, 0.10214292329253936, 0.23181127243740748, 0.4925989539294909, 0.1738584543280556, 0.11590563621870374, 0.35155662865886356, 0.2929638572157196, 0.13183373574707383, 0.2197228929117897, 0.34147442893347013, 0.3932129787718747, 0.11382480964449006, 0.1448679395475328, 0.2959112498983931, 0.36692994987400745, 0.1420373999512287, 0.20121964993090732, 0.23821751478260822, 0.3335045206956515, 0.2540986824347821, 0.16675226034782575, 0.267032938722526, 0.2861067200598493, 0.2861067200598493, 0.17166403203590958, 0.21982943640010058, 0.2839463553501299, 0.41218019325018856, 0.09159559850004191, 0.41809417187980347, 0.3094982830798545, 0.08959160825995789, 0.1818981137399145, 0.2188230273262881, 0.3805617866544141, 0.29493538465717095, 0.10465449132996388, 0.2878901231878906, 0.2981719133017438, 0.2673265429601841, 0.1439450615939453, 0.3451774745426343, 0.3451774745426343, 0.12944155295348786, 0.18337553335077447, 0.4614901724425168, 0.31949319630635775, 0.10649773210211926, 0.12424735411913913, 0.38467259152429323, 0.26927081406700526, 0.1538690366097173, 0.23080355491457594, 0.48162387709918847, 0.19831571409966586, 0.14165408149976133, 0.1699848977997136, 0.38627820195454177, 0.3632168167632258, 0.14413365744572454, 0.10377623336092166, 0.20108351954971995, 0.4775733589305849, 0.17594807960600498, 0.15081263966228997, 0.2303072825615599, 0.5373836593103064, 0.15353818837437327, 0.11515364128077996, 0.27924500169347194, 0.48030140291277174, 0.11169800067738878, 0.13403760081286653, 0.329399659810234, 0.3659996220113711, 0.07319992440227423, 0.21959977320682267, 0.3539129346454749, 0.3273694645470643, 0.19022820237194277, 0.12386952712591622, 0.23592191770540502, 0.47184383541081004, 0.16333055841143423, 0.12249791880857568, 0.4210216521155747, 0.3381977205518551, 0.06901994296976635, 0.17254985742441586, 0.28106938000158294, 0.25551761818325724, 0.28106938000158294, 0.17886233272828006, 0.20504284344675014, 0.3690771182041503, 0.3075642651701252, 0.12302570606805009, 0.4612893006576901, 0.34224690048796363, 0.10416210014851067, 0.10416210014851067, 0.32168525132286835, 0.22977517951633453, 0.2757302154196014, 0.1378651077098007, 0.4590389693653951, 0.19673098687088364, 0.1639424890590697, 0.1639424890590697, 0.5657303767248874, 0.16639128727202568, 0.16639128727202568, 0.13311302981762055, 0.5028733735559083, 0.2681991325631511, 0.13409956628157554, 0.10057467471118166, 0.26821140363302926, 0.4376080796117846, 0.1976294553085479, 0.09881472765427395, 0.33603195325400775, 0.3935111031527196, 0.1370656651430821, 0.1370656651430821, 0.2537726702683041, 0.46524989549189083, 0.21147722522358675, 0.0845908900894347, 0.441214465685657, 0.18577451186764504, 0.13933088390073378, 0.2322181398345563, 0.4994586542987373, 0.2875671039901821, 0.09081066441795224, 0.12108088589060298, 0.2967314439046112, 0.5026267315118924, 0.11505913130995128, 0.07872466879101929, 0.1797385549105226, 0.40441174854867584, 0.22467319363815322, 0.22467319363815322, 0.2657677141533772, 0.18983408153812656, 0.3986515712300658, 0.15186726523050123, 0.2877898266937841, 0.10278208096206576, 0.41112832384826303, 0.18500774573171835, 0.4050384436157739, 0.29556859398988905, 0.15325778947623878, 0.15325778947623878, 0.45206873088422017, 0.1977800697618463, 0.05650859136052752, 0.2825429568026376, 0.27936456474726135, 0.4952371829610542, 0.08888872514685588, 0.12698389306693697, 0.3976915356305433, 0.37638663193604993, 0.07811798021314244, 0.1420326912966226, 0.3728433697549986, 0.30505366616318064, 0.2146673947074234, 0.11298283931969653, 0.4421155989276823, 0.28966194412503327, 0.15245365480264908, 0.13720828932238416, 0.49095996640039685, 0.23566078387219047, 0.13746879059211112, 0.13746879059211112, 0.35855429407303363, 0.3323186140189092, 0.1399236269553302, 0.1661593070094546, 0.28676568109747197, 0.262868541006016, 0.215074260823104, 0.23897140091455998, 0.31404847505671113, 0.3701285598882667, 0.14580822056204445, 0.15702423752835556, 0.21959055758602913, 0.32938583637904373, 0.23788977071819822, 0.21959055758602913, 0.3021091012304235, 0.24168728098433878, 0.33232001135346584, 0.12084364049216939, 0.30785545842277345, 0.3196960529774955, 0.17760891832083084, 0.20129010743027495, 0.2275355776617282, 0.500578270855802, 0.18202846212938256, 0.1365213465970369, 0.515451680560412, 0.2319532562521854, 0.1030903361120824, 0.1546355041681236, 0.23916342714743288, 0.349546547369325, 0.2575606138510816, 0.14717749362918947, 0.41610510718177307, 0.274251093369805, 0.11348321104957448, 0.19859561933675535, 0.2550295388586733, 0.2550295388586733, 0.1854760282608533, 0.3245830494564933, 0.32560848474736587, 0.236806170725357, 0.2516065563956918, 0.17760462804401775, 0.587310986081762, 0.16314194057826722, 0.06525677623130689, 0.16314194057826722, 0.3796963533796244, 0.21461098234500509, 0.2888993993105838, 0.1155597597242335, 0.3045852915827174, 0.39830384283893816, 0.09371855125622074, 0.19915192141946908, 0.2927411026882731, 0.23419288215061845, 0.2927411026882731, 0.17564466161296385, 0.5001200201619088, 0.2500600100809544, 0.09377250378035791, 0.18754500756071582, 0.24086491146110997, 0.32115321528147994, 0.20072075955092497, 0.24086491146110997, 0.3961735237953428, 0.4225850920483657, 0.10564627301209142, 0.10564627301209142, 0.25012874357382026, 0.3335049914317604, 0.26203963612495457, 0.1667524957158802, 0.30701724392820834, 0.3591522476141305, 0.17957612380706525, 0.16219778924509118, 0.4528662587733563, 0.16353503789037865, 0.20127389278815835, 0.17611465618963856, 0.24550231031538025, 0.4364485516717871, 0.13639017239743348, 0.19094624135640687, 0.22019959892589133, 0.35782434825457343, 0.3027744485231006, 0.11009979946294567, 0.46724191541452575, 0.25159180060782155, 0.17970842900558684, 0.10782505740335209, 0.4529783855145492, 0.28311149094659327, 0.137511295602631, 0.12942239586129978, 0.354995355511844, 0.31555142712163914, 0.11833178517061468, 0.21694160614612693, 0.3768473742806251, 0.29310351332937506, 0.08374386095125003, 0.2512315828537501, 0.27732221754226377, 0.35655713684005347, 0.1584698385955793, 0.23770475789336898, 0.44723696266571833, 0.25556397866612474, 0.14056018826636862, 0.15333838719967485, 0.37958563701210524, 0.26178319793938293, 0.2225157182484755, 0.13089159896969146, 0.24822189186434562, 0.4255232431960211, 0.10638081079900527, 0.21276162159801054, 0.4489135111871066, 0.28217420703189555, 0.16673930415521102, 0.10260880255705293, 0.4098961918042771, 0.32550579937398477, 0.1687807848605847, 0.09644616277747697, 0.5339406850065561, 0.22247528541939837, 0.08899011416775934, 0.13348517125163903, 0.19307559625960202, 0.3990228989365109, 0.29604924759805645, 0.11584535775576121, 0.39409867802277354, 0.25767990486104425, 0.10610349023690056, 0.25767990486104425, 0.349554513311696, 0.24968179522264003, 0.06658181205937068, 0.3162636072820107, 0.3159821773328449, 0.2934120218090702, 0.2934120218090702, 0.09028062209509853, 0.3593647635949341, 0.19765061997721375, 0.2695235726962006, 0.17968238179746704, 0.3203829934150004, 0.30703370202270874, 0.24028724506125032, 0.14684220531520853, 0.3006233735293769, 0.4774606520760692, 0.08841863927334614, 0.14146982283735385, 0.21289272708720997, 0.33116646435788216, 0.16558323217894108, 0.2838569694496133, 0.4794573172133979, 0.23972865860669895, 0.10274085368858527, 0.1712347561476421, 0.48433032990706937, 0.32288688660471293, 0.12108258247676734, 0.08072172165117823, 0.3401187809983367, 0.32221779252474003, 0.10740593084158, 0.23271285015675666, 0.20465535660569523, 0.40931071321139045, 0.27287380880759365, 0.10232767830284761, 0.2323668323103055, 0.3319526175861507, 0.26556209406892056, 0.16597630879307534, 0.29959198241173435, 0.4743539721519128, 0.12482999267155599, 0.0998639941372448, 0.4600245378998742, 0.32001706984339073, 0.12000640119127153, 0.1000053343260596, 0.38633602339616796, 0.18243645549263485, 0.19316801169808398, 0.2360942365198804, 0.2656774043079092, 0.28338923126176985, 0.3188128851694911, 0.12398278867702431, 0.3096989674951833, 0.3096989674951833, 0.27528797110682957, 0.1032329891650611, 0.3092816502777841, 0.4329943103888977, 0.12371266011111362, 0.13144470136805822, 0.3504344935341679, 0.266997709359366, 0.25031035252440564, 0.133498854679683, 0.3866538059756963, 0.30207328591851274, 0.18124397155110764, 0.14499517724088612, 0.3202628174637033, 0.2846780599677362, 0.1423390299838681, 0.2490933024717692, 0.2567261815524694, 0.43322543136979214, 0.1283630907762347, 0.19254463616435205, 0.3213596042383719, 0.2719196651247762, 0.14831981734078703, 0.2719196651247762, 0.5462645535934518, 0.17250459587161637, 0.11500306391441091, 0.17250459587161637, 0.4208778980238717, 0.24551210718059183, 0.19290236992760787, 0.1402926326746239, 0.40263283093861346, 0.23263230232008777, 0.178947924861606, 0.178947924861606, 0.3065196903946893, 0.3065196903946893, 0.13932713199758603, 0.22292341119613765, 0.5093195395219979, 0.24946263160261126, 0.10134419408856082, 0.14032273027646883], \"Term\": [\"absoluto\", \"absoluto\", \"absoluto\", \"absoluto\", \"acabar\", \"acabar\", \"acabar\", \"acabar\", \"actividad\", \"actividad\", \"actividad\", \"actividad\", \"afirmar\", \"afirmar\", \"afirmar\", \"afirmar\", \"amor\", \"amor\", \"amor\", \"amor\", \"ano\", \"ano\", \"ano\", \"ano\", \"antiguo\", \"antiguo\", \"antiguo\", \"antiguo\", \"bien\", \"bien\", \"bien\", \"bien\", \"buen\", \"buen\", \"buen\", \"buen\", \"cambio\", \"cambio\", \"cambio\", \"cambio\", \"camino\", \"camino\", \"camino\", \"camino\", \"campo\", \"campo\", \"campo\", \"campo\", \"capacidad\", \"capacidad\", \"capacidad\", \"capacidad\", \"capaz\", \"capaz\", \"capaz\", \"capaz\", \"casa\", \"casa\", \"casa\", \"casa\", \"caso\", \"caso\", \"caso\", \"caso\", \"celebrar\", \"celebrar\", \"celebrar\", \"celebrar\", \"cerebro\", \"cerebro\", \"cerebro\", \"cerebro\", \"chomsky\", \"chomsky\", \"chomsky\", \"chomsky\", \"ciencia\", \"ciencia\", \"ciencia\", \"ciencia\", \"cientifico\", \"cientifico\", \"cientifico\", \"cientifico\", \"ciudad\", \"ciudad\", \"ciudad\", \"ciudad\", \"cognitivo\", \"cognitivo\", \"cognitivo\", \"cognitivo\", \"complejo\", \"complejo\", \"complejo\", \"complejo\", \"comprender\", \"comprender\", \"comprender\", \"comprender\", \"comun\", \"comun\", \"comun\", \"comun\", \"conocido\", \"conocido\", \"conocido\", \"conocido\", \"considerar\", \"considerar\", \"considerar\", \"considerar\", \"consistir\", \"consistir\", \"consistir\", \"consistir\", \"contar\", \"contar\", \"contar\", \"contar\", \"cosa\", \"cosa\", \"cosa\", \"cosa\", \"cuestion\", \"cuestion\", \"cuestion\", \"cuestion\", \"cultura\", \"cultura\", \"cultura\", \"cultura\", \"cultural\", \"cultural\", \"cultural\", \"cultural\", \"dado\", \"dado\", \"dado\", \"dado\", \"dar\", \"dar\", \"dar\", \"dar\", \"deber\", \"deber\", \"deber\", \"deber\", \"desarrollar\", \"desarrollar\", \"desarrollar\", \"desarrollar\", \"deseo\", \"deseo\", \"deseo\", \"deseo\", \"diccionario\", \"diccionario\", \"diccionario\", \"diccionario\", \"dicho\", \"dicho\", \"dicho\", \"dicho\", \"disciplina\", \"disciplina\", \"disciplina\", \"disciplina\", \"dudar\", \"dudar\", \"dudar\", \"dudar\", \"efecto\", \"efecto\", \"efecto\", \"efecto\", \"ejemplo\", \"ejemplo\", \"ejemplo\", \"ejemplo\", \"elemento\", \"elemento\", \"elemento\", \"elemento\", \"escrito\", \"escrito\", \"escrito\", \"escrito\", \"especie\", \"especie\", \"especie\", \"especie\", \"espiritu\", \"espiritu\", \"espiritu\", \"espiritu\", \"estructura\", \"estructura\", \"estructura\", \"estructura\", \"existencia\", \"existencia\", \"existencia\", \"existencia\", \"explicar\", \"explicar\", \"explicar\", \"explicar\", \"facultad\", \"facultad\", \"facultad\", \"facultad\", \"filosofia\", \"filosofia\", \"filosofia\", \"filosofia\", \"filosofico\", \"filosofico\", \"filosofico\", \"filosofico\", \"filosofo\", \"filosofo\", \"filosofo\", \"filosofo\", \"forma\", \"forma\", \"forma\", \"forma\", \"formar\", \"formar\", \"formar\", \"formar\", \"frase\", \"frase\", \"frase\", \"frase\", \"freud\", \"freud\", \"freud\", \"freud\", \"generativo\", \"generativo\", \"generativo\", \"generativo\", \"gramatico\", \"gramatico\", \"gramatico\", \"gramatico\", \"gran\", \"gran\", \"gran\", \"gran\", \"grande\", \"grande\", \"grande\", \"grande\", \"habiar\", \"habiar\", \"habiar\", \"habiar\", \"habrio\", \"habrio\", \"habrio\", \"habrio\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hecho\", \"hecho\", \"hecho\", \"hecho\", \"hipotesis\", \"hipotesis\", \"hipotesis\", \"hipotesis\", \"historia\", \"historia\", \"historia\", \"historia\", \"historico\", \"historico\", \"historico\", \"historico\", \"hombre\", \"hombre\", \"hombre\", \"hombre\", \"humano\", \"humano\", \"humano\", \"humano\", \"idea\", \"idea\", \"idea\", \"idea\", \"importante\", \"importante\", \"importante\", \"importante\", \"inconsciente\", \"inconsciente\", \"inconsciente\", \"inconsciente\", \"intelectual\", \"intelectual\", \"intelectual\", \"intelectual\", \"interior\", \"interior\", \"interior\", \"interior\", \"interno\", \"interno\", \"interno\", \"interno\", \"joven\", \"joven\", \"joven\", \"joven\", \"justo\", \"justo\", \"justo\", \"justo\", \"lengua\", \"lengua\", \"lengua\", \"lengua\", \"lenguaje\", \"lenguaje\", \"lenguaje\", \"lenguaje\", \"lenguo\", \"lenguo\", \"lenguo\", \"lenguo\", \"ley\", \"ley\", \"ley\", \"ley\", \"libro\", \"libro\", \"libro\", \"libro\", \"linguistico\", \"linguistico\", \"linguistico\", \"linguistico\", \"logico\", \"logico\", \"logico\", \"logico\", \"luis\", \"luis\", \"luis\", \"luis\", \"madre\", \"madre\", \"madre\", \"madre\", \"manera\", \"manera\", \"manera\", \"manera\", \"medico\", \"medico\", \"medico\", \"medico\", \"medio\", \"medio\", \"medio\", \"medio\", \"mente\", \"mente\", \"mente\", \"mente\", \"modo\", \"modo\", \"modo\", \"modo\", \"momento\", \"momento\", \"momento\", \"momento\", \"mucho\", \"mucho\", \"mucho\", \"mucho\", \"mundo\", \"mundo\", \"mundo\", \"mundo\", \"natural\", \"natural\", \"natural\", \"natural\", \"naturaleza\", \"naturaleza\", \"naturaleza\", \"naturaleza\", \"nino\", \"nino\", \"nino\", \"nino\", \"nivel\", \"nivel\", \"nivel\", \"nivel\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"numero\", \"numero\", \"numero\", \"numero\", \"nunca\", \"nunca\", \"nunca\", \"nunca\", \"objeto\", \"objeto\", \"objeto\", \"objeto\", \"obra\", \"obra\", \"obra\", \"obra\", \"orden\", \"orden\", \"orden\", \"orden\", \"padre\", \"padre\", \"padre\", \"padre\", \"paris\", \"paris\", \"paris\", \"paris\", \"parte\", \"parte\", \"parte\", \"parte\", \"pensamiento\", \"pensamiento\", \"pensamiento\", \"pensamiento\", \"placer\", \"placer\", \"placer\", \"placer\", \"poco\", \"poco\", \"poco\", \"poco\", \"politico\", \"politico\", \"politico\", \"politico\", \"posibilidad\", \"posibilidad\", \"posibilidad\", \"posibilidad\", \"posible\", \"posible\", \"posible\", \"posible\", \"primero\", \"primero\", \"primero\", \"primero\", \"principio\", \"principio\", \"principio\", \"principio\", \"problema\", \"problema\", \"problema\", \"problema\", \"producir\", \"producir\", \"producir\", \"producir\", \"pronto\", \"pronto\", \"pronto\", \"pronto\", \"propio\", \"propio\", \"propio\", \"propio\", \"psicoanalisis\", \"psicoanalisis\", \"psicoanalisis\", \"psicoanalisis\", \"publico\", \"publico\", \"publico\", \"publico\", \"puesto\", \"puesto\", \"puesto\", \"puesto\", \"punto\", \"punto\", \"punto\", \"punto\", \"querer\", \"querer\", \"querer\", \"querer\", \"racional\", \"racional\", \"racional\", \"racional\", \"razon\", \"razon\", \"razon\", \"razon\", \"realidad\", \"realidad\", \"realidad\", \"realidad\", \"recibir\", \"recibir\", \"recibir\", \"recibir\", \"regla\", \"regla\", \"regla\", \"regla\", \"religion\", \"religion\", \"religion\", \"religion\", \"religioso\", \"religioso\", \"religioso\", \"religioso\", \"representacion\", \"representacion\", \"representacion\", \"representacion\", \"rey\", \"rey\", \"rey\", \"rey\", \"saber\", \"saber\", \"saber\", \"saber\", \"seguir\", \"seguir\", \"seguir\", \"seguir\", \"sentimiento\", \"sentimiento\", \"sentimiento\", \"sentimiento\", \"seriar\", \"seriar\", \"seriar\", \"seriar\", \"serio\", \"serio\", \"serio\", \"serio\", \"sexual\", \"sexual\", \"sexual\", \"sexual\", \"significado\", \"significado\", \"significado\", \"significado\", \"sintaxi\", \"sintaxi\", \"sintaxi\", \"sintaxi\", \"sistema\", \"sistema\", \"sistema\", \"sistema\", \"social\", \"social\", \"social\", \"social\", \"sociedad\", \"sociedad\", \"sociedad\", \"sociedad\", \"sujeto\", \"sujeto\", \"sujeto\", \"sujeto\", \"tener\", \"tener\", \"tener\", \"tener\", \"teoria\", \"teoria\", \"teoria\", \"teoria\", \"termino\", \"termino\", \"termino\", \"termino\", \"tiempo\", \"tiempo\", \"tiempo\", \"tiempo\", \"tierra\", \"tierra\", \"tierra\", \"tierra\", \"tipo\", \"tipo\", \"tipo\", \"tipo\", \"unico\", \"unico\", \"unico\", \"unico\", \"universal\", \"universal\", \"universal\", \"universal\", \"ver\", \"ver\", \"ver\", \"ver\", \"vida\", \"vida\", \"vida\", \"vida\", \"vivir\", \"vivir\", \"vivir\", \"vivir\", \"voltaire\", \"voltaire\", \"voltaire\", \"voltaire\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 3, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el60181406938292344641688428898\", ldavis_el60181406938292344641688428898_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el60181406938292344641688428898\", ldavis_el60181406938292344641688428898_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el60181406938292344641688428898\", ldavis_el60181406938292344641688428898_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.011085  0.006843       1        1  34.786916\n",
       "3     -0.002494 -0.012497       2        1  33.001933\n",
       "2      0.021288  0.003044       3        1  16.795092\n",
       "1     -0.007710  0.002610       4        1  15.416059, topic_info=           Term        Freq       Total Category  logprob  loglift\n",
       "129       frase  109.000000  109.000000  Default  30.0000  30.0000\n",
       "7       chomsky  246.000000  246.000000  Default  29.0000  29.0000\n",
       "311       freud  368.000000  368.000000  Default  28.0000  28.0000\n",
       "126  estructura  108.000000  108.000000  Default  27.0000  27.0000\n",
       "59        deber  116.000000  116.000000  Default  26.0000  26.0000\n",
       "..          ...         ...         ...      ...      ...      ...\n",
       "126  estructura   16.253749  108.671492   Topic4  -5.1220  -0.0302\n",
       "144      teoria   17.144011  129.331953   Topic4  -5.0687  -0.1510\n",
       "132       hacer   18.310744  173.450119   Topic4  -5.0028  -0.3786\n",
       "79          ver   15.549404  114.047329   Topic4  -5.1663  -0.1228\n",
       "72       propio   15.514745  123.626208   Topic4  -5.1685  -0.2057\n",
       "\n",
       "[257 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "252       1  0.361465  absoluto\n",
       "252       2  0.225916  absoluto\n",
       "252       3  0.180732  absoluto\n",
       "252       4  0.225916  absoluto\n",
       "267       1  0.309139    acabar\n",
       "...     ...       ...       ...\n",
       "266       4  0.222923     vivir\n",
       "335       1  0.509320  voltaire\n",
       "335       2  0.249463  voltaire\n",
       "335       3  0.101344  voltaire\n",
       "335       4  0.140323  voltaire\n",
       "\n",
       "[644 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 3, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt = LdaMulticore(corpus = corpus,\n",
    "    id2word = dictionary,\n",
    "    num_topics = 4,\n",
    "    random_state=123)\n",
    "pyLDAvis.enable_notebook()\n",
    "LDA_visualization = gensimvis.prepare(lda_model_opt, corpus, dictionary)\n",
    "LDA_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados sugieren que hay 3 tipos de tópicos en estas páginas. Los 3 encontrados anteriormente, y páginas que hablan sobre estos 3 autores simultáneamente.\n",
    "\n",
    "Es importante destacar que la medida de coherencia  no es sólo del tema en sí, sino también del conjunto de datos que se utiliza como referencia. Asimismo, parte de la literatura suele favorecerla ya que lleva a mejor interpretabilidad que otras medidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medida de Perplejidad\n",
    "\n",
    "Otra de las medidas utilizadas, es la medida de Perplejidad. A diferencia de la medida de coherencia lo que buscaremos es minimizar la perplejidad.\n",
    "\n",
    "Esta medida calcula el número de palabras diferentes que son igualmente probables a seguir a cualquier palabra dada. Para aclarar qué queremos decir con esto, consideremos un ejemplo con 2 palabras: *el* y *anunciar*. La palabra *el* puede anteceder a una gran cantidad de palabras de igual probabilidad, mientras que el número de palabras de igual probabilidad que anteceden a *anunciar* será relativamente menor. \n",
    "\n",
    "La idea intuitiva es que palabras que, en promedio, pueden ir seguidas de un menor número de palabras de igual probabilidad, son más específicas y por lo tanto  pueden estar más estrechamente vinculadas a los tópicos. Entonces puntuaciones más bajas de perplejidad implican mejores modelos de lenguaje.\n",
    "\n",
    "El cálculo es sencillo usando  [gensim](https://radimrehurek.com/gensim/index.html); ya que tanto [LDAModel](https://radimrehurek.com/gensim/models/ldamodel.html?highlight=ldamodel#module-gensim.models.ldamode)  como  [LdaMulticore](https://radimrehurek.com/gensim/models/ldamulticore.html) retornan el límite por palabra de la verosimilitud, por lo que para convertirlo en perplejidad necesitamos hacer $perplejidad=2^{(-limite)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.72978311890707"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp2(-lda_model_opt.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que nos interesa minimizar esta perplejidad comparemos esta medida para distinto números de tópicos. Crearemos entonces una función similar a la que construimos en la sección anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplejidad_ntopicos(dictionary, corpus, texts, start=1, limit=10, step=1):\n",
    " \n",
    "    perplejidad_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=num_topics, \n",
    "                        random_state=123,\n",
    "                        passes=20)\n",
    "        model_list.append(model)\n",
    "        perplejidad_values.append(np.exp2(-model.log_perplexity(corpus)))\n",
    "\n",
    "    return model_list, perplejidad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos, valores_p = perplejidad_ntopicos(dictionary=dictionary, corpus=corpus, texts=clean, start=1, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Show graph\n",
    "limit=10; start=1; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, valores_p)\n",
    "plt.xlabel(\"Número de Tópicos\")\n",
    "plt.ylabel(\"Medida de Perplejidad\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos entonces un resultado análogo al anterior. En este caso ambos indicadores coinciden, pero a priori esto no tiene que ser así. En la práctica se tienden a utilizar ambos e indican el rango de posibles valores. Por esta razón, es recomendable calcular los 2 y en función de los resultados unidos al conocimiento del investigador decidir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones Finales\n",
    "\n",
    "Cuando queremos extraer información de una colección de documentos, el modelado de tópicos es un enfoque que puede ser potencialmente útil, ya que proporciona información sobre la estructura subyacente de los documentos. \n",
    "\n",
    "En este sentido los modelos de tópicos se pueden usar para predecir los tópicos que pertenecen a documentos no vistos. Si vamos a hacer predicciones, es importante reconocer que los modelos de tópicos sólo conocen las palabras que se usan para entrenarlos. Es decir, si los documentos no vistos tienen palabras que no estaban en los datos de entrenamiento, el modelo no podrá procesar esas palabras incluso si se vinculan a uno de los tópicos identificados en los datos de entrenamiento. Debido a este hecho, los modelos de tópicos tienden a usarse más para el análisis exploratorio y la inferencia que para la predicción.\n",
    "\n",
    "Cuando se analiza el modelado de tópicos, es importante reforzar continuamente el hecho de que los grupos de palabras que representan los tópicos no están relacionados conceptualmente; están relacionados solo por proximidad. La proximidad frecuente de ciertas palabras en los documentos es suficiente para definir tópicos debido a que estamos asumiendo que todas las palabras en el mismo documento están relacionadas.\n",
    "\n",
    "Sin embargo, esta suposición puede no ser cierta o las palabras pueden ser demasiado genéricas para formar tópicos coherentes. La interpretación de tópicos abstractos implica equilibrar las características innatas de los datos de texto con las agrupaciones de palabras generadas. Los datos de texto, y el lenguaje en general, son muy variables, complejos y contextuales, lo que significa que cualquier resultado generalizado debe interpretarse con cautela.\n",
    "\n",
    "Es importante tener en cuenta también que la naturaleza ruidosa de los datos de texto puede hacer que los modelos de tópico asignen palabras no relacionadas con uno de los tópicos a ese tópico en particular. Esto no es necesariamente una falla en el modelo. En cambio, es una característica que, dados datos ruidosos, el modelo podría extraer peculiaridades de los datos que podrían afectar negativamente los resultados. Las correlaciones espurias podrían ser el resultado de cómo, dónde o cuándo se recopilaron los datos. \n",
    "\n",
    "Esto no es para minimizar o invalidar los resultados del modelo. Dados documentos cuidadosamente limpios y una cantidad adecuada de tópicos, las agrupaciones de palabras, como vimos, pueden ser una buena guía sobre lo que contiene un corpus y pueden incorporarse de manera efectiva en sistemas de datos más grandes como ser los sistemas de recomendación vistos en este módulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- Banik, R. (2018). Hands-on recommendation systems with Python: start building powerful and personalized, recommendation engines with Python. Packt Publishing Ltd.\n",
    "\n",
    "- Blei, D. M., Jordan, M. I., &; Ng, A. Y. (2003). Latent Dirichlet Allocation. JMLR.org, 3, 993–1022. https://doi.org/10.5555/944919.944937 \n",
    "\n",
    "- Fradejas Rueda, J. M. (2020). Cuentapalabras. Estilometrıa y análisis de texto con R para filólogos.\n",
    "\n",
    "- Hoffman, M., Bach, F., & Blei, D. (2010). Online learning for latent dirichlet allocation. advances in neural information processing systems, 23.\n",
    "\n",
    "- Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press.\n",
    "\n",
    "- Patel, A. A. (2019). Hands-on unsupervised learning using Python: how to build applied machine learning solutions from unlabeled data. O'Reilly Media.\n",
    "\n",
    "- Rehurek, R., & Sojka, P. (2011). Gensim–python framework for vector space modeling. NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic, 3(2).\n",
    "\n",
    "- Röder, M., Both, A., & Hinneburg, A. (2015). Exploring the space of topic coherence measures. In Proceedings of the eighth ACM international conference on Web search and data mining (pp. 399-408)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe36d3cf18f454bb22b210d1ce52ae8c21a1b2f0a9257a143474ae90bef14b60"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
