{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado Colaborativo Basado en Items: Análisis de Canasta de Compra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *cuaderno* trata sobre el Análisis de Canastas de Compra o *Market Basket Analysis* en inglés. Este es un algoritmo que ayuda a los vendedores a comprender las preferencias de sus clientes y mejorar sus sistemas de recomendación basado en los ítems comprados.  Si bien este  puede no estar a la vanguardia de los algoritmos de aprendizaje no supervizado, es omnipresente y es innegable su impacto en los negocios.  El objetivo del *cuaderno* es que usted aprenda que es el análisis de canasta de compra, los conceptos teóricos y el algoritmo que lo implementa, reconociendo sus  características y funcionamiento, y cómo ejecutarlo.\n",
    "\n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Sin embargo, los ejemplos contienen celdas con código ejecutable (`en gris`), que podrá modificar  libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los códigos de ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es  análisis de canasta de compra?\n",
    "\n",
    "El análisis de canasta de compra consiste en buscar reglas de asociación en los consumos de individuos. La idea general es identificar y cuantificar qué items, o grupos de items, son consumidos juntos con la suficiente frequencia que nos permita entender el comportamiento de los clientes. \n",
    "\n",
    "Antes de sumergirnos en los detalles matemáticos y del algoritmo, tenemos que definir el término canasta de compra: *Una canasta de compra es un conjunto permanente de productos en un sistema económico*. Permanente no significa necesariamente permanente en el sentido tradicional. Significa, que hasta el momento en que el producto sea retirado del catálogo, estará siempre disponible para su compra. El producto al que se hace referencia en la definición anterior es cualquier bien, servicio o elemento de un grupo, incluida una bicicleta, escuchar una canción, pintar su casa o un sitio web. Por último, un sistema económico puede ser una empresa, un conjunto de actividades, o un país.\n",
    "\n",
    "Este tipo de análisis suele aplicarse en tres casos principalmente:\n",
    "\n",
    "1. Recomendaciones de productos, cupones y descuentos. \n",
    "2. Mejora de precios. \n",
    "3. Distribución espacial de los productos en las tiendas. \n",
    "\n",
    "\n",
    "Las recomendaciones de productos, cupones y descuentos, y la mejora de precios son dos caras de la misma moneda. Imaginemos el caso de dos artículos fuertemente relacionados, lo más probable es que estos dos artículos se compren en la misma transacción. Una forma de aumentar la rentabilidad de esa transacción sería aumentando el precio de uno de los productos. Si la asociación entre los dos artículos es lo suficientemente fuerte, el aumento de precio puede ser tal que no incurra en el riesgo que no se compre ninguno de los artículos. \n",
    "\n",
    "De manera similar, los comerciantes pueden alentar a los clientes a comprar un artículo débilmente asociado con otro a través de descuentos o cupones.  Por ejemplo,  al estudiar los historiales de compras de ciertos clientes se podría encontrar que estos están comprando artículos que están débilmene asociados con otros productos que no están comprando. Con esta información, se pueden ofrecer descuentos e inducir a que los compren, aumentando por lo tanto las ventas.\n",
    "\n",
    "Asimismo, las asociaciones de productos se pueden explotar para colocar productos estrategicamente en las tiendas y lograr que los clientes compren más artículos, gastando más dinero.\n",
    "\n",
    "\n",
    "El ejemplo más sencillo de una canasta de compras es un supermercado, que es un sistema compuesto por una colección de alimentos y bebidas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:500px\">\n",
    "<img src = \"figs/fig0.jpeg\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso sin usar ningún modelo o análisis, ciertas relaciones de productos son obvias. Tomemos la relación entre la carne y las verduras (por lo general, los modelos de análisis de la canasta de compra arrojan relaciones más específicas que la que existe entre la carne y las verduras, pero, supongamos por un momento que esta es así)\n",
    "\n",
    "Dada esta relación, ¿qué podemos hacer? Bueno, sabemos que estos artículos se compran juntos frequentemente. Podemos entonces aprovechar esta información colocando las verduras y las carnes en lados opuestos de la tienda, obligando a los consumidores a caminar toda la  tienda, aumentando la probabilidad de que compren artículos adicionales que no hubiesen comprado de otra forma. Obviamente, son muchos factores que determinan el diseño de la tienda, pero el análisis de la canasta de compra es definitivamente uno de ellos.\n",
    "\n",
    "En el análisis de la canasta de compra entonces estamos buscando grupos de productos que ocurren con frecuencia.  Por lo tanto, se podría pensar en este análisis como uno de clustering. Sin embargo, la principales diferencias son que los grupos en el análisis de la canasta de compra son micro (solo unos pocos productos por grupo) y que el orden de los artículos en el grupo es importante cuando se trata de calcular métricas probabilísticas. \n",
    "\n",
    "El mensaje final de esta sección, es que el analista puede  descubrir relaciones, obvias y sorprendentes, entre  productos y que una vez descubiertas, estas se pueden explotar para informar y mejorar el proceso de toma de decisiones. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reglas de asociación \n",
    "\n",
    "\n",
    "Como dijimos anteriormente, el análisis de la canasta de compra busca de manera eficiente reglas de asociación en los datos. Pero antes de seguir tenemos que definir que es una regla de asociación:\n",
    "\n",
    "*Una regla de asociación es un caso en el que la probabilidad condicional del producto A dado que también compra el producto B es alta, mucho más alta que la probabilidad incondicional del producto A. Por ejemplo, tal vez cuando compra leche, también compra pan. Si sólo compra pan después de comprar leche, entonces habrá una regla de asociación: leche $\\rightarrow$ pan. Sin embargo, si siempre compra pan independientemente de leche, entonces la probabilidad de comprar pan será alta, pero esta no es una regla de asociación, porque la leche no hace una diferencia.*\n",
    "\n",
    "Cada una de estas probabilidades que componen la regla de asociación recibe un nombre particular en este contexto, las 5 métricas más importantes son: soporte, confianza,  \"lift\", levante, y convicción.\n",
    "\n",
    "\n",
    "   - El **soporte**  es la probabilidad de comprar el artículo:\n",
    "   \\begin{align}\n",
    "        soporte = Pr(X)\n",
    "   \\end{align}\n",
    "   - La **confianza** es la probabilidad condicional:\n",
    "    \\begin{align}\n",
    "      confianza= Pr(X|Y)\n",
    "    \\end{align}\n",
    "   - El **lift** es un indicador que busca responder la pregunta: si un individuo compra el producto Y, ¿podemos decir algo acerca de si comprará o no el producto X con cierto nivel de confianza?. Se calcula como el cociente de la confianza y el soporte:\n",
    "    \\begin{align}\n",
    "         lift= \\frac{Pr(X|Y)}{Pr(X)}=\\frac{Pr(X,Y)}{Pr(X)Pr(Y)}\n",
    "    \\end{align}\n",
    "    Su rango es  $[0,\\infty]$ y nos da una medida del aumento de la probabilidad conjunta relativa a lo que esperaríamos si X y Y fuesen independientes. \n",
    "   - El **levante** o **apalancamiento** por otro lado es un indicador que toma la diferencia:\n",
    "    \\begin{align}\n",
    "         apalancamiento=Pr(X,Y)-Pr(X)Pr(Y)\n",
    "    \\end{align}\n",
    "    Su rango es $[-1,1]$ y nos va a dar la dirección de la relación entre los items: valores postivos implican una asociación positiva, mientras que valores negativos indican una asociación negativa.\n",
    "   - La **convicción** es un indicador que se forma con el ratio de: \n",
    "       - la probabilidad de que X ocurra sin Y, si X e Y son independientes. \n",
    "       - la frecuencia observada de las predicciones incorrectas.   \n",
    "    \\begin{align}\n",
    "         convicción=\\frac{1-Pr(Y)}{1-Pr(X|Y)}\n",
    "    \\end{align}\n",
    "    \n",
    " Su rango es $[0, \\infty]$. Los valores del indicador superiores a 1 son ideales porque implica que la asociación entre X e Y es incorrecta más a menudo que si la asociación entre X e Y es aleatoria ($X \\perp Y$). En otras palabras, esto quiere decir que existe la asociación entre X e Y. Un valor de 1 implica independencia, y un valor menor a 1 significa que la relación que indica que X e Y son  independientes es correcta con más frecuencia que la relación X e Y que se ha definido como X$\\rightarrow$ Y. En esta situación, la relación podría ser inversa Y $\\rightarrow$X. \n",
    "     \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo cálculo de las métricas\n",
    "\n",
    "Ilustremos cómo calcular estas métricas en `Python` utilizando datos de 10 transacciones ficticias. Cada una de las entradas de la lista es una transacción y cada elemento es el producto que se compró en cada transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "transacciones = [\n",
    "     ['leche', 'pan', 'manzanas', 'cereales', 'gelatina', 'galletas', 'ensalada', 'tomates'],\n",
    "     ['cerveza', 'leche', 'papas', 'salsa', 'uvas', 'vino', 'papas', 'huevos', 'zanahorias'],\n",
    "     ['pañales', 'fórmula para bebés', 'leche', 'pan', 'pollo', 'espárragos', 'galletas'],\n",
    "     ['leche', 'galletas', 'pollo', 'espárragos', 'brócoli', 'cereales', 'jugo de naranja'],\n",
    "     ['filete', 'espárragos', 'brócoli', 'papas fritas', 'salsa', 'ketchup', 'patatas', 'ensalada'],\n",
    "     ['cerveza', 'salsa', 'espárragos', 'vino', 'queso', 'galletas', 'fresas', 'galletas'],\n",
    "     ['torta de chocolate', 'frutillas', 'vino', 'queso', 'cerveza', 'leche', 'jugo de naranja'],\n",
    "     ['pollo', 'porotos', 'brócoli', 'leche', 'pan', 'huevos', 'patatas', 'ketchup', 'galletas saladas'],\n",
    "     ['huevos', 'pan', 'queso', 'pavo', 'ensalada', 'tomates', 'vino', 'tapa de asado', 'zanahorias'],\n",
    "     ['pan', 'leche', 'tomates', 'cereal', 'pollo', 'pavo', 'papas fritas', 'salsa', 'pañales']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay 10 transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(transacciones)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regla de asociación que queremos evaluar en este ejemplo es la de leche $\\rightarrow$ pan. Para ello, necesitamos calcular las frecuencias de compras de cada uno de los artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 10\n",
      "Freq(leche) = 7\n",
      "Freq(pan) = 5\n",
      "Freq(leche, pan) = 4\n"
     ]
    }
   ],
   "source": [
    "# Frecuencia de compra de leche\n",
    "f_x = sum(['leche' in i for i in transacciones])\n",
    "# Frecuencia de compra de pan\n",
    "f_y = sum(['pan' in i for i in transacciones])\n",
    "# Frecuencia de compra de leche y pan\n",
    "f_x_y = sum([\n",
    "    all(w in i for w in ['leche', 'pan']) \n",
    "    for i in transacciones\n",
    "])\n",
    "\n",
    "print(\n",
    "    \"N = {}\\n\".format(N) + \n",
    "    \"Freq(leche) = {}\\n\".format(f_x) + \n",
    "    \"Freq(pan) = {}\\n\".format(f_y) + \n",
    "    \"Freq(leche, pan) = {}\".format(f_x_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soporte = 0.4\n"
     ]
    }
   ],
   "source": [
    "# Soporte (supp)\n",
    "soporte = f_x_y / N\n",
    "print(\"Soporte = {}\".format(round(soporte, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confianza = 0.5714\n"
     ]
    }
   ],
   "source": [
    "# Confianza: x -> y\n",
    "\n",
    "confianza = soporte / (f_x / N)\n",
    "print(\"Confianza = {}\".format(round(confianza, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift = 1.1429\n"
     ]
    }
   ],
   "source": [
    "# Lift: x -> y\n",
    "\n",
    "lift = confianza / (f_y / N)\n",
    "print(\"Lift = {}\".format(round(lift, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apalancamiento = 0.05\n"
     ]
    }
   ],
   "source": [
    "# Apalancamiento: x -> y\n",
    "\n",
    "apalancamiento = soporte - ((f_x / N) * (f_y / N))\n",
    "print(\"Apalancamiento = {}\".format(round(apalancamiento, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convicción = 1.1667\n"
     ]
    }
   ],
   "source": [
    "# Convicción: x -> y\n",
    "\n",
    "conviccion = (1 - (f_y / N)) / (1 - confianza)\n",
    "print(\"Convicción = {}\".format(round(conviccion, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algortimo Apriori\n",
    "\n",
    "Las reglas de asociación con un indicador de *lift* alto son las más útiles, pues suelen revelar asociaciones que no conocemos de antemano. No existe, sin embargo, una teoría subyacente sobre estas regalas de asociación. En la práctica, lo que hacemos, es explorar los datos y buscar pares de productos, o grupos de productos que tengan indicadores altos de *confianza* y *lift*.\n",
    "\n",
    "Operacionalmente esta exploración se hace utilizando el algoritmo de Apriori, que tiene dos etapas:\n",
    "\n",
    "    1. Identificar todos los productos que ocurren con una frecuencia por encima de un determinado límite (productos frecuentes).\n",
    "    2. Convertir esos productos frecuentes en reglas de asociación.\n",
    "\n",
    "Es importante notar que este límite debe ser predeterminado, es un hiper-parámetro del algoritmo, y puede ser ajustado por quién lo ejecuta. Sin embargo, esto no es un valor que pueda ser optimizado ya que no hay una métrica de evaluación para este algoritmo. Este hiper-parámetro suele especificarse en función de los datos, el uso particular, o la experiencia del analista.\n",
    "\n",
    "\n",
    "La idea principal detrás de este algoritmo es el principio Apriori: cualquier subconjunto de un conjunto de elementos frecuentes debe ser frecuente. De forma paralela, ningún superconjunto de un conjunto de elementos infrecuentes puede ser frecuente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para illustar como funciona, veamos un ejercicio simple. Supongamos que tenemos los siguientes datos de un comercio que vende 4 productos (A,B,C,D), tenemos 7 transacciones y podemos ver que productos se compraron en la misma transaccion (en la misma canasta de compra).\n",
    "\n",
    "\n",
    "| Transacción | Productos    |\n",
    "|-------------|--------------|\n",
    "| 1           | {A, B, C, D} |\n",
    "| 2           | {A, B, D}    |\n",
    "| 3           | {A, B}       |\n",
    "| 4           | {B, C, D}    |\n",
    "| 5           | {B, C}       |\n",
    "| 6           | {C, D}       |\n",
    "| 7           | {B, D}       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la tabla de datos podemos ver que el producto A aparece en 3 de las 7 transacciones, el artículo B en 6 y ambos artículos juntos en 3. El soporte del producto {A} es por lo tanto del 43%, el del producto {B} del 86% y del conjunto {A, B} del 43%. De las 3 transacciones que incluyen A, las 3 incluyen B, por lo tanto, la regla “clientes que compran el artículo A también compran B”, se cumple, acorde a los datos, un 100% de las veces. Esto significa que la confianza de la regla A $\\rightarrow$ B es del 100\\%.\n",
    "\n",
    "Encontrar conjuntos de artículos frecuentes (conjuntos de artículos con una frecuencia mayor o igual a un determinado soporte mínimo) no es un proceso trivial ya que los conjuntos posibles crecen exponencialmente. Para illustarlo veamos todas las posibles combinaciones de estos 4 artículos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"max-width:500px\">\n",
    "<img src = \"figs/fig1.jpeg\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las flechas indican que dos o más conjuntos puden ser combinados para formar un conjunto más grande. Recordemos que nuestro objetivo es encontrar los productos que se compran juntos frequentemente; y que la frecuencia la medimos con el indicador de soporte que cuenta el porcentaje de transacciones que contienen a este producto. Entonces, ¿cómo calculamos el soporte del conjunto {A,B}? En este caso tendríamos que examinar todas las transacciones y contar el total de veces que aparece este cojunto, para luego dividirlo por el total de transacciones. \n",
    "\n",
    "Esto deberíamos además hacerlo para todos los conjuntos posibles. En la figura podemos ver que para cada conjunto posible debemos ir a través de los datos 15 veces. Es más, para un conjunto de datos que contiene N items posibles puede generar $2^N-1$ conjuntos posibles. Por ejemplo, para una tienda que vende solo 100 artículos, uno puede generar $1.26\\times 10^{30}$ posibles conjutos. Esto demandaría demasiados recursos computacionales y de tiempo. \n",
    "\n",
    "Para reducir los costos computacionales podemos aplicar el principio Apriori: cualquier subconjunto de un conjunto de elementos frecuentes debe ser frecuente. Esto implica por ejemplo que si {A,B} es frecuente, también lo son {A} y {B}. Entonces, lo que hace el algoritmo Apriori es buscar exhaustivamente por niveles de complejidad (de menor a mayor tamaño de conjunto de productos). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El funcionamiento del algoritmo es relativamente sencillo, comienza identificando los productos individuales que aparecen en el total de transacciones con una frecuencia por encima de un límite minimo establecido por el analista. \n",
    "\n",
    "Supongamos que el límite que establecemos es que el soporte tiene que ser igual o superior a 3/7 = 0.43, es decir que el item aparezca al menos en 3 de las 7 transacciones. A continuación lo que hacemos es calcular el soporte para los conjuntos de productos que contienen los items individuales:\n",
    "\n",
    "| Conjunto de Productos | \tOcurrencias \t| Soporte |\n",
    "| --------------| ------------------| --------| \n",
    "| {A}           | \t3               | \t0.43  | \n",
    "| {B}    \t    |   6               | \t0.86  |\n",
    "| {C}    \t    |   4               | \t0.57  |\n",
    "| {D}    \t    |   5               | \t0.71  |\n",
    "\n",
    "\n",
    "Dado que todos los items superan este umbral se mantienen en la base. Luego generamos los conjuntos que tienen todos las combinaciones de tamaño 2 y calculamos soporte:\n",
    "\n",
    "\n",
    "| Conjunto de Productos | \tOcurrencias \t| Soporte |\n",
    "| --------------| ------------------| --------| \n",
    "| {A, B}        | 3                 |\t0.43 |\n",
    "| {A, C}        |\t1               |\t0.14  |\n",
    "| {A, D}        |\t2               |\t0.29  |\n",
    "| {B, C}        |\t3               |\t0.43  |\n",
    "| {B, D}        |\t4               |\t0.57  |\n",
    "| {C, D}        |\t3               |\t0.43  |\n",
    "\n",
    "Los conjutos {A, B}, {B, C}, {B, D} y {C, D} superan el límite establecido, por lo que son frecuentes. Los restantes conjuntos se descartan, lo que implica además que cualquier conjunto futuro que los contenga no va a ser frecuente.\n",
    "\n",
    "| Conjunto de Productos | \tOcurrencias \t| Soporte |\n",
    "| --------------| ------------------| --------| \n",
    "|  {A, B}       |\t3              \t| 0.43    |\n",
    "|  {B, C}       |\t3              \t| 0.43    |\n",
    "|  {B, D}       |\t4              \t| 0.57    |\n",
    "|  {C, D}       |\t3              \t| 0.43    |\n",
    "\n",
    "Continuamos el proceso calculando para los conjuntos con 3 elementos que contienen A, B y C:\n",
    "\n",
    "| Conjunto de Productos |\n",
    "|---------------|\n",
    "| {A, B, C}     |\n",
    "| {A, B, D}     |\n",
    "| {B, C, D}     |\n",
    "| {C, D, A}     |\n",
    "\n",
    "Los conjuntos {A, B, C}, {A, B, D} y {C, D, A} contienen subconjuntos que ya habiamos identificado como infrecuentes, por lo que los descartamos. Para el conjunto restante calculamos el soporte:\n",
    "\n",
    "\n",
    "| Conjunto de Productos |  \tOcurrencias \t| Soporte |\n",
    "| --------------| ------------------| --------| \n",
    "| {B, C, D} \t|         2 \t    | 0.29    |\n",
    "\n",
    "El soporte del conjunot {B, C, D} no supera el umbral que establecimos y lo declaramos infrecuente. Al no existir ningún nuevo conjunto frecuente, se detiene el algoritmo.\n",
    "\n",
    "Como resultado de la búsqueda se han identificado los siguientes itemsets frecuentes:\n",
    "\n",
    "|Conjuntos frecuentes |\n",
    "|-------------------|\n",
    "| {A, B}            |\n",
    "| {B, C}            |\n",
    "| {B, D}            |\n",
    "| {C, D}            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificados los conjuntos frequentes, en el siguiente paso calculamos las reglas de asociación. Nuevamete, este paso es demandante puesto que para cada conjunto frequente se generan tantas reglas como combinaciones binarias. Imponer un límite en la confianza reduce el conjunto de items a verificar. En concreto, el proceso a seguir es el siguiente:\n",
    "\n",
    "   -  Por cada conjunto frecuente $I$, obtenemos todos los posibles subconjuntos de $I$.\n",
    "\n",
    "   -  Para cada subconjuntos $s$ de $I$, creamos la regla “s => (I-s)”\n",
    "\n",
    "   - Descartamos todas las reglas que no superen un mínimo de confianza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando con nuestro ejemplo, supongamos que solo queremos las reglas que tienen una confianza superior al 0.7. \n",
    "\n",
    "\n",
    "\n",
    "| Reglas \t         |  Confianza \t        |    Confianza       |\n",
    "|--------------------|----------------------|--------------------|\n",
    "| $$A\\rightarrow B$$  |\t$\\frac{Pr(A, B)}{Pr(A)}$  | 0.43 / 0.43 = 1    |\n",
    "| $B \\rightarrow A$  |\t$\\frac{Pr(A, B)}{Pr(B)}$  | 0.43 / 0.86 = 0.5  |\n",
    "| $B \\rightarrow C$  |\t$\\frac{Pr(B, C)}{Pr(B)}$  | 0.43 / 0.86 = 0.5  |\n",
    "| $C \\rightarrow B$  |\t$\\frac{Pr(B, C)}{Pr(C)}$  | 0.43 / 0.57 = 0.75 |\n",
    "| $B \\rightarrow D$  |\t$\\frac{Pr(B, D)}{Pr(B)}$  | 0.43 / 0.86 = 0.5  |\n",
    "| $D \\rightarrow B$  |\t$\\frac{Pr(B, D)}{Pr(D)}$  | 0.43 / 0.71 = 0.6  |\n",
    "| $C \\rightarrow D$  |\t$\\frac{Pr(C, D)}{Pr(C)}$  | 0.43 / 0.57 = 0.75 |\n",
    "| $D \\rightarrow C$  |\t$\\frac{Pr(C, D)}{Pr(D)}$  | 0.43 / 0.71 = 0.6  |\n",
    "\n",
    "De todas las posibles reglas, únicamente $C \\rightarrow D$ y $C \\rightarrow B$ superan el límite de confianza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo implementación algoritmo Apriori\n",
    "\n",
    "Para ilustrar la implementación en `Phyton` vamos a utilizar datos de `lastfm` que es un servicio de radio online. Estos datos contienen la lista de reproducción para 15.000 usuarios.\n",
    "\n",
    "Para esta tarea vamos a usar la libreria `apriori`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos y visualizamos la primeras observaciones de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usuario</th>\n",
       "      <th>artista</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the black dahlia murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>goldfrapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dropkick murphys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>le tigre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   usuario                  artista\n",
       "0        1    red hot chili peppers\n",
       "1        1  the black dahlia murder\n",
       "2        1                goldfrapp\n",
       "3        1         dropkick murphys\n",
       "4        1                 le tigre"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfm = pd.read_csv('data/lastfm_es.csv')\n",
    "lastfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `apriori` requiere que los datos estén en un formato de listas de listas, donde todo el conjunto de datos es una lista grande y cada transacción  es una lista interna dentro de la lista grande externa. Actualmente tenemos datos en forma `data.frame` de pandas. Así, con el siguiente bucle lo convertimos en el formato deseado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in lastfm['usuario'].unique():\n",
    "    records.append(list(lastfm[lastfm['usuario'] == i]['artista'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo el primer usuario escuchó a los siguientes artistas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red hot chili peppers',\n",
       " 'the black dahlia murder',\n",
       " 'goldfrapp',\n",
       " 'dropkick murphys',\n",
       " 'le tigre',\n",
       " 'schandmaul',\n",
       " 'edguy',\n",
       " 'jack johnson',\n",
       " 'eluveitie',\n",
       " 'the killers',\n",
       " 'judas priest',\n",
       " 'rob zombie',\n",
       " 'john mayer',\n",
       " 'the who',\n",
       " 'guano apes',\n",
       " 'the rolling stones']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es aplicar el algoritmo Apriori en el conjunto de datos. Para hacerlo, podemos usar la clase `apriori` que importamos de la libreria `apriori`. La clase apriori requiere algunos valores de parámetros para funcionar:\n",
    "\n",
    "   1. El primer parámetro es la lista de listas de la que se desea extraer reglas. \n",
    "   2. El segundo parámetro es el parámetro `min_support`. Este parámetro se utiliza para seleccionar los elementos con valores de soporte superiores al valor especificado por el parámetro. \n",
    "   3. El parámetro `min_confidence` filtra aquellas reglas que tienen una confianza superior al umbral de confianza especificado por el parámetro. \n",
    "   3. De manera similar, el parámetro `min_lift` especifica el valor de elevación mínimo para las reglas preseleccionadas. \n",
    "   4. Finalmente, el parámetro `min_length` especifica la cantidad mínima de elementos que desea en sus reglas.\n",
    "\n",
    "Supongamos que queremos reglas sólo para aquellos artistas que se escuchan al menos 1% de las veces. La confianza mínima para las reglas es 50% o 0.5. De manera similar, especificamos el valor de lift como 8 y finalmente `min_length` es 5, ya que queremos al menos cinco artistas escuchados en nuestras reglas. Recordemos que la elección de estos valores es un tanto arbitraria y por lo tanto los invito a experimentar con distintos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(records, min_support=0.01, min_confidence=0.5, min_lift=8,min_length=5)\n",
    "association_results = list(association_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cuantas reglas de asociación derivamos a partir de estos parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivamos 4 reglas de asociación.\n"
     ]
    }
   ],
   "source": [
    "print(\"Derivamos {} reglas de asociación.\".format(len(association_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento que obtuvimos contiene tres items. Primero muestra la regla de asociación, por ejemplo en este caso Judas Priest se escucha a menudo con Iron Maiden. El valor de soporte es 0.01, que nos dice que el 1% de los usuarios escucharon judas priest. El nivel de confianza es .5 que muestra que de los usuarios que escucharon Judas Priest, el 50% también escucho Iron Maiden. Finalmente, el lift de 8.56 nos dice que Iron Maiden es 8.56 veces más probables que sea escuchado por los clientes que escuchan Judas Priest, comparado a la probabilidad base de escuchar Iron Maiden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelationRecord(items=frozenset({'iron maiden', 'judas priest'}), support=0.013533333333333333, ordered_statistics=[OrderedStatistic(items_base=frozenset({'judas priest'}), items_add=frozenset({'iron maiden'}), confidence=0.5075, lift=8.56299212598425)])\n"
     ]
    }
   ],
   "source": [
    "print(association_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los sistemas de recomendación pueden entonces recoger estas reglas de asociación y sugerir contenido basado en ellas. A los clientes que escucharon Judas Priest, se les puede entonces recomendar Iron Maiden. Finalmente podemos ver todas las reglas de asociación derivadas anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regla: iron maiden -> judas priest\n",
      "Soporte: 0.013533333333333333\n",
      "Confianza: 0.5075\n",
      "Lift: 8.56299212598425\n",
      "=====================================\n",
      "Regla: kanye west -> t.i.\n",
      "Soporte: 0.0104\n",
      "Confianza: 0.5672727272727273\n",
      "Lift: 8.854413016743923\n",
      "=====================================\n",
      "Regla: sonata arctica -> nightwish\n",
      "Soporte: 0.013466666666666667\n",
      "Confianza: 0.51010101010101\n",
      "Lift: 8.236291874612649\n",
      "=====================================\n",
      "Regla: the pussycat dolls -> rihanna\n",
      "Soporte: 0.0104\n",
      "Confianza: 0.5777777777777778\n",
      "Lift: 13.415892672858618\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for item in association_results:\n",
    "\n",
    "    #Primer índice de la lista interna\n",
    "    #Contiene elemento base y el adicional\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"Regla: \" + items[0] + \" -> \" + items[1])\n",
    "\n",
    "    #Segundo índice de la lista interna\n",
    "    print(\"Soporte: \" + str(item[1]))\n",
    "\n",
    "    #Tercer índice de la lista ubicada en 0th\n",
    "    #del tercer índice de la lista interna\n",
    "\n",
    "    print(\"Confianza: \" + str(item[2][0][2]))\n",
    "    print(\"Lift: \" + str(item[2][0][3]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "\n",
    "- Amat Rodrigo, Joaquín. (2018). Reglas de asociación y algoritmo Apriori con R, available under a Attribution 4.0 International (CC BY 4.0) at https://www.cienciadedatos.net/documentos/43_reglas_de_asociacion. Accedido el 12 de Enero de 2022\n",
    "\n",
    "- Harrington, Peter (2012). Machine learning in action. Simon and Schuster.\n",
    "\n",
    "- Jones, Aaron; Kruger, Christopher; Johnston, Benjamin. The Unsupervised Learning Workshop: Get started with unsupervised learning algorithms and simplify your unorganized data to help make future predictions. Packt Publishing. Kindle Edition. \n",
    "\n",
    "- Taddy, Matt; Taddy, Matt. Business Data Science: Combining Machine Learning and Economics to Optimize, Automate, and Accelerate Business Decisions. McGraw-Hill Education. Kindle Edition. \n",
    "\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
